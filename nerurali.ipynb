{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "# from transformers import BertTokenizer, TFBertModel\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Dataset, DataLoader,TensorDataset\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import KFold\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train=pd.read_csv('C:/Users/divya/OneDrive/Documents/UTAUSTIN/Semester 6/461p/ECE-461P-Term-Project/train_pp32.csv' ,delimiter=',')\n",
    "# test=pd.read_csv('C:/Users/divya/OneDrive/Documents/UTAUSTIN/Semester 6/461p/ECE-461P-Term-Project/test_pp32.csv' ,delimiter=',')\n",
    "\n",
    "train=pd.read_csv('C:/Users/divya/OneDrive/Documents/UTAUSTIN/Semester 6/461p/ECE-461P-Term-Project/train_pp2.csv' ,delimiter=',')\n",
    "test=pd.read_csv('C:/Users/divya/OneDrive/Documents/UTAUSTIN/Semester 6/461p/ECE-461P-Term-Project/test_pp2.csv' ,delimiter=',')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = train.drop(columns=['price'])\n",
    "y = ((train['price'])) # talk about this \n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train.astype(np.float32)).to(device)\n",
    "X_test_tensor = torch.tensor(X_test.astype(np.float32)).to(device)\n",
    "y_train_tensor = torch.tensor(y_train.values.astype(np.float32)).to(device)\n",
    "y_test_tensor = torch.tensor(y_test.values.astype(np.float32)).to(device)\n",
    "\n",
    "# # Reshape y tensors to have the correct shape (n_samples, 1)\n",
    "y_train_tensor = y_train_tensor.view(-1, 1)\n",
    "y_test_tensor = y_test_tensor.view(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create datasets\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "def rmsle_loss(y_pred, y_true):\n",
    "    # Add a small constant to avoid taking log of zero\n",
    "    epsilon = 1e-6\n",
    "    y_pred = torch.clamp(y_pred, min=epsilon, max=1e9)  # Clamp predictions to avoid log(0)\n",
    "    y_true = torch.clamp(y_true, min=epsilon, max=1e9)\n",
    "    return torch.sqrt(torch.mean((torch.log1p(y_pred) - torch.log1p(y_true)) ** 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import CyclicLR\n",
    "\n",
    "def train_model(model, train_loader, test_loader, num_epochs=5):\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-6, momentum=0.8)\n",
    "    scheduler = CyclicLR(optimizer, base_lr=1e-6, max_lr=0.1, step_size_up=5*len(train_loader),\n",
    "                     mode='triangular', cycle_momentum=False)\n",
    "\n",
    "\n",
    "    min_train_rmsle = float('inf')\n",
    "    min_test_rmsle = float('inf')\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = rmsle_loss(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()  # Update learning rate at each batch\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "        avg_train_rmsle = total_train_loss / len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        total_test_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in test_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                test_loss = rmsle_loss(outputs, targets)\n",
    "                total_test_loss += test_loss.item()\n",
    "\n",
    "        avg_test_rmsle = total_test_loss / len(test_loader)\n",
    "\n",
    "        if avg_train_rmsle < min_train_rmsle:\n",
    "            min_train_rmsle = avg_train_rmsle\n",
    "        if avg_test_rmsle < min_test_rmsle:\n",
    "            min_test_rmsle = avg_test_rmsle\n",
    "\n",
    "        print(f'Epoch {epoch+1}: Train RMSLE = {avg_train_rmsle}, Test RMSLE = {avg_test_rmsle} , Current LR = {scheduler.get_last_lr()}')\n",
    "\n",
    "    print(f'Minimum Train RMSLE so far: {min_train_rmsle}')\n",
    "    print(f'Minimum Test RMSLE so far: {min_test_rmsle}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_model(model, train_loader, test_loader, num_epochs=50):\n",
    "#     model.to(device)\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "#     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "\n",
    "#     for epoch in range(num_epochs):\n",
    "#         model.train()\n",
    "#         total_train_loss = 0\n",
    "#         for inputs, targets in train_loader:\n",
    "#             inputs, targets = inputs.to(device), targets.to(device)\n",
    "#             optimizer.zero_grad()\n",
    "#             outputs = model(inputs)\n",
    "#             loss = rmsle_loss(outputs, targets)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             total_train_loss += loss.item()\n",
    "\n",
    "#         avg_train_rmsle = total_train_loss / len(train_loader)\n",
    "#         total_test_loss = 0\n",
    "#         model.eval()\n",
    "#         with torch.no_grad():\n",
    "#             for inputs, targets in test_loader:\n",
    "#                 inputs, targets = inputs.to(device), targets.to(device)\n",
    "#                 outputs = model(inputs)\n",
    "#                 test_loss = rmsle_loss(outputs, targets)\n",
    "#                 total_test_loss += test_loss.item()\n",
    "\n",
    "#         avg_test_rmsle = total_test_loss / len(test_loader)\n",
    "#         scheduler.step(avg_test_rmsle)\n",
    "\n",
    "#         print(f'Epoch {epoch+1}: Train RMSLE = {avg_train_rmsle}, Test RMSLE = {avg_test_rmsle}')\n",
    "\n",
    "#     print(f'Best Test RMSLE so far: {scheduler.best}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = X_train.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PricePredictionModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size=1):\n",
    "        super(PricePredictionModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, 256)\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.layer2 = nn.Linear(256, 128)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.layer3 = nn.Linear(128, 64)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        self.dropout3 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.layer4 = nn.Linear(64, 32)\n",
    "        self.bn4 = nn.BatchNorm1d(32)\n",
    "        self.dropout4 = nn.Dropout(0.1)\n",
    "        \n",
    "        self.output_layer = nn.Linear(32, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.layer1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.relu(self.bn2(self.layer2(x)))\n",
    "        x = self.dropout2(x)\n",
    "        x = torch.relu(self.bn3(self.layer3(x)))\n",
    "        x = self.dropout3(x)\n",
    "        x = torch.relu(self.bn4(self.layer4(x)))\n",
    "        x = self.dropout4(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train RMSLE = 0.7103170956413825, Test RMSLE = 0.6860611839599665\n",
      "Epoch 2: Train RMSLE = 0.6905549636505591, Test RMSLE = 0.6841801157286848\n",
      "Epoch 3: Train RMSLE = 0.6894629118511327, Test RMSLE = 0.683762296058531\n",
      "Epoch 4: Train RMSLE = 0.6887406774495348, Test RMSLE = 0.6837902820019699\n",
      "Epoch 5: Train RMSLE = 0.6881720342230563, Test RMSLE = 0.6835961619336686\n",
      "Epoch 6: Train RMSLE = 0.6878651257972417, Test RMSLE = 0.6838404884550311\n",
      "Epoch 7: Train RMSLE = 0.6876620969280219, Test RMSLE = 0.6838252511346595\n",
      "Epoch 8: Train RMSLE = 0.6873545684333386, Test RMSLE = 0.6835608863926338\n",
      "Epoch 9: Train RMSLE = 0.6868888843362309, Test RMSLE = 0.6832752976677257\n",
      "Epoch 10: Train RMSLE = 0.6866839122186246, Test RMSLE = 0.6832874632584035\n",
      "Best Test RMSLE so far: 0.6832752976677257\n"
     ]
    }
   ],
   "source": [
    "model = PricePredictionModel(num_features).to(device)\n",
    "\n",
    "# Use the training function already provided\n",
    "train_model(model, train_loader, test_loader, num_epochs=10)\n",
    "\n",
    "#Epoch 5: Train RMSLE = 0.6883012584179728, Test RMSLE = 0.6835928453002499\n",
    "# Best Test RMSLE so far: 0.6832752976677257\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedPricePredictionModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size=1):\n",
    "        super(EnhancedPricePredictionModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, 512)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.layer2 = nn.Linear(512, 256)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.dropout2 = nn.Dropout(0.1)\n",
    "        \n",
    "        self.layer3 = nn.Linear(256, 128)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.dropout3 = nn.Dropout(0.1)\n",
    "        \n",
    "        self.layer4 = nn.Linear(128, 64)\n",
    "        self.bn4 = nn.BatchNorm1d(64)\n",
    "        self.dropout4 = nn.Dropout(0.1)\n",
    "        \n",
    "        self.output_layer = nn.Linear(64, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.layer1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.relu(self.bn2(self.layer2(x)))\n",
    "        x = self.dropout2(x)\n",
    "        x = torch.relu(self.bn3(self.layer3(x)))\n",
    "        x = self.dropout3(x)\n",
    "        x = torch.relu(self.bn4(self.layer4(x)))\n",
    "        x = self.dropout4(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EnhancedPricePredictionModel(num_features).to(device)\n",
    "\n",
    "# Use the training function already provided\n",
    "train_model(model, train_loader, test_loader, num_epochs=10)\n",
    "# Epoch 1: Train RMSLE = 0.701097307975991, Test RMSLE = 0.6841780046707775\n",
    "# Epoch 2: Train RMSLE = 0.6888048825449483, Test RMSLE = 0.6840163404823544\n",
    "# Epoch 3: Train RMSLE = 0.6878524877785998, Test RMSLE = 0.683792892498503\n",
    "# Epoch 4: Train RMSLE = 0.6872429579799324, Test RMSLE = 0.683677059799721\n",
    "# Epoch 5: Train RMSLE = 0.6869078011756413, Test RMSLE = 0.6837233345654394\n",
    "# Epoch 6: Train RMSLE = 0.6863807070894459, Test RMSLE = 0.6837847139004105"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train.astype(np.float32)).unsqueeze(1)  # Add sequence dimension\n",
    "X_test_tensor = torch.tensor(X_test.astype(np.float32)).unsqueeze(1)  # Add sequence dimension\n",
    "y_train_tensor = torch.tensor(y_train.values.astype(np.float32)).view(-1, 1)\n",
    "y_test_tensor = torch.tensor(y_test.values.astype(np.float32)).view(-1, 1)\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, sequence_length, input_dim)\n",
    "        out, _ = self.rnn(x)  # out shape: (batch_size, sequence_length, hidden_dim)\n",
    "        out = out[:, -1, :]  # get the last sequence output\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, sequence_length, input_dim)\n",
    "        out, (hn, cn) = self.lstm(x)  # out shape: (batch_size, sequence_length, hidden_dim)\n",
    "        out = out[:, -1, :]  # get the last sequence output\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train RMSLE = 0.9801828821023003, Test RMSLE = 0.7010385301054224 , Current LR = [0.02000080000000002]\n",
      "Epoch 2: Train RMSLE = 0.6950768298166766, Test RMSLE = 0.6910986202384739 , Current LR = [0.0400006]\n",
      "Epoch 3: Train RMSLE = 0.6902512350930401, Test RMSLE = 0.6890711715005972 , Current LR = [0.06000040000000001]\n",
      "Epoch 4: Train RMSLE = 0.6891211542877781, Test RMSLE = 0.6887067230965405 , Current LR = [0.0800002]\n",
      "Epoch 5: Train RMSLE = 0.6886812580246937, Test RMSLE = 0.6881854928252444 , Current LR = [0.1]\n",
      "Epoch 6: Train RMSLE = 0.6884077206164756, Test RMSLE = 0.6878372403099855 , Current LR = [0.0800002]\n",
      "Epoch 7: Train RMSLE = 0.6881301104061287, Test RMSLE = 0.6875795655843301 , Current LR = [0.06000040000000001]\n",
      "Epoch 8: Train RMSLE = 0.6876860214244988, Test RMSLE = 0.6875404149767607 , Current LR = [0.0400006]\n",
      "Epoch 9: Train RMSLE = 0.6875653081028397, Test RMSLE = 0.6874087602929898 , Current LR = [0.02000080000000002]\n",
      "Epoch 10: Train RMSLE = 0.6873640940228356, Test RMSLE = 0.6873739421027812 , Current LR = [1e-06]\n",
      "Minimum Train RMSLE so far: 0.6873640940228356\n",
      "Minimum Test RMSLE so far: 0.6873739421027812\n"
     ]
    }
   ],
   "source": [
    "model = LSTMModel(input_dim=num_features, hidden_dim=10, output_dim=1).to(device)  # Adjust dimensions as necessary\n",
    "train_model(model, train_loader, test_loader, num_epochs=10)\n",
    "# Best Test RMSLE so far: 0.6883052102114385\n",
    "\n",
    "# Minimum Train RMSLE so far: 0.6873640940228356\n",
    "# Minimum Test RMSLE so far: 0.6873739421027812\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train RMSLE = 0.89248368301251, Test RMSLE = 0.6959494175987978 , Current LR = [0.02000080000000002]\n",
      "Epoch 2: Train RMSLE = 0.6926944601239902, Test RMSLE = 0.6905906675866166 , Current LR = [0.0400006]\n",
      "Epoch 3: Train RMSLE = 0.690474758986654, Test RMSLE = 0.6897507240505324 , Current LR = [0.06000040000000001]\n",
      "Epoch 4: Train RMSLE = 0.6898817215179194, Test RMSLE = 0.6892154644029093 , Current LR = [0.0800002]\n",
      "Epoch 5: Train RMSLE = 0.6897256960639672, Test RMSLE = 0.6890912703248082 , Current LR = [0.1]\n",
      "Epoch 6: Train RMSLE = 0.6893705928934606, Test RMSLE = 0.6886392525592259 , Current LR = [0.0800002]\n",
      "Epoch 7: Train RMSLE = 0.6889364930379092, Test RMSLE = 0.6883083894828228 , Current LR = [0.06000040000000001]\n",
      "Epoch 8: Train RMSLE = 0.6886863322390908, Test RMSLE = 0.6880548574035549 , Current LR = [0.0400006]\n",
      "Epoch 9: Train RMSLE = 0.6883312759964292, Test RMSLE = 0.6878094568014474 , Current LR = [0.02000080000000002]\n",
      "Epoch 10: Train RMSLE = 0.6880693981135202, Test RMSLE = 0.6876124085880347 , Current LR = [1e-06]\n",
      "Minimum Train RMSLE so far: 0.6880693981135202\n",
      "Minimum Test RMSLE so far: 0.6876124085880347\n"
     ]
    }
   ],
   "source": [
    "model = RNNModel(input_dim=num_features, hidden_dim=10, output_dim=1).to(device)  # Adjust dimensions as necessary\n",
    "train_model(model, train_loader, test_loader, num_epochs=10)\n",
    "#Best Test RMSLE so far: 0.9206008657493835\n",
    "\n",
    "# Minimum Train RMSLE so far: 0.6880693981135202\n",
    "# Minimum Test RMSLE so far: 0.6876124085880347"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class RBNFModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers=1):\n",
    "        super(RBNFModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.batch_norm = nn.BatchNorm1d(hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, sequence_length, input_dim)\n",
    "        out, (hn, cn) = self.lstm(x)  # out shape: (batch_size, sequence_length, hidden_dim)\n",
    "        out = out[:, -1, :]  # we only use the output of the last time step\n",
    "        out = self.batch_norm(out)\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train RMSLE = 0.8608611680359589, Test RMSLE = 0.6921516187288222 , Current LR = [0.02000080000000002]\n",
      "Epoch 2: Train RMSLE = 0.691954627581605, Test RMSLE = 0.6891397957708725 , Current LR = [0.0400006]\n",
      "Epoch 3: Train RMSLE = 0.6908542909358015, Test RMSLE = 0.6892781519918666 , Current LR = [0.06000040000000001]\n",
      "Epoch 4: Train RMSLE = 0.6904197056202591, Test RMSLE = 0.688713728794577 , Current LR = [0.0800002]\n",
      "Epoch 5: Train RMSLE = 0.6902876732756371, Test RMSLE = 0.6883867871847825 , Current LR = [0.1]\n",
      "Epoch 6: Train RMSLE = 0.6900170087999694, Test RMSLE = 0.6879308694598999 , Current LR = [0.0800002]\n",
      "Epoch 7: Train RMSLE = 0.6896799886313844, Test RMSLE = 0.6888296482588969 , Current LR = [0.06000040000000001]\n",
      "Epoch 8: Train RMSLE = 0.6892936175813106, Test RMSLE = 0.6877083220540365 , Current LR = [0.0400006]\n",
      "Epoch 9: Train RMSLE = 0.6889687462666292, Test RMSLE = 0.6873600878434175 , Current LR = [0.02000080000000002]\n",
      "Epoch 10: Train RMSLE = 0.6887654505139725, Test RMSLE = 0.6873131738441437 , Current LR = [1e-06]\n",
      "Minimum Train RMSLE so far: 0.6887654505139725\n",
      "Minimum Test RMSLE so far: 0.6873131738441437\n"
     ]
    }
   ],
   "source": [
    "model = RBNFModel(input_dim=num_features, hidden_dim=10, output_dim=1).to(device)  # Adjust dimensions as necessary\n",
    "train_model(model, train_loader, test_loader, num_epochs=10)\n",
    "\n",
    "# Minimum Train RMSLE so far: 0.6887654505139725\n",
    "# Minimum Test RMSLE so far: 0.6873131738441437"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytorch-tabnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from pytorch_tabnet.callbacks import Callback\n",
    "\n",
    "X = train.drop(columns=['price'])\n",
    "y = np.log1p((train['price'])) # talk about this \n",
    "\n",
    "# Initialize TabNetRegressor\n",
    "model = TabNetRegressor(device_name='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25, random_state=42)\n",
    "\n",
    "class RMSELogCallback(Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_pred = self.model.predict(self.valid_data[0])\n",
    "        val_rmse = sqrt(mean_squared_error(self.valid_data[1], val_pred))\n",
    "        print(f\"Epoch {epoch + 1} - Validation RMSE: {val_rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Usage of the callback\n",
    "model.fit(\n",
    "  X_train, y_train,\n",
    "  eval_set=[(X_test, y_test)],\n",
    "  eval_name=['eval'],\n",
    "  eval_metric=['rmse'],\n",
    "  max_epochs=1000,\n",
    "  patience=50,\n",
    "  batch_size=1024,\n",
    "  virtual_batch_size=128,\n",
    "  num_workers=0,\n",
    "  drop_last=False,\n",
    "  callbacks=[RMSELogCallback()]  # Assuming this works similar to Keras callbacks\n",
    ")\n",
    "# Predict and evaluate\n",
    "predictions = model.predict(X_test)\n",
    "rmse = sqrt(mean_squared_error(y_test, predictions))\n",
    "print(f\"Test RMSE: {rmse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
