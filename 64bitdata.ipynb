{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "# from transformers import BertTokenizer, TFBertModel\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Dataset, DataLoader,TensorDataset\n",
    "import torch.nn as nn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train=pd.read_csv('C:/Users/divya/OneDrive/Documents/UTAUSTIN/Semester 6/461p/ECE-461P-Term-Project/train_pp32.csv' ,delimiter=',')\n",
    "# test=pd.read_csv('C:/Users/divya/OneDrive/Documents/UTAUSTIN/Semester 6/461p/ECE-461P-Term-Project/test_pp32.csv' ,delimiter=',')\n",
    "\n",
    "# train=pd.read_csv('C:/Users/divya/OneDrive/Documents/UTAUSTIN/Semester 6/461p/ECE-461P-Term-Project/train_pp2.csv' ,delimiter=',')\n",
    "# test=pd.read_csv('C:/Users/divya/OneDrive/Documents/UTAUSTIN/Semester 6/461p/ECE-461P-Term-Project/test_pp2.csv' ,delimiter=',')\n",
    "train= pd.read_csv('/Users/dkamboj6/Recitation/ECE-461P-Term-Project/train_pp2.csv')\n",
    "test=pd.read_csv('/Users/dkamboj6/Recitation/ECE-461P-Term-Project/test_pp2.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = train.drop(columns=['price'])\n",
    "y = ((train['price'])) # talk about this \n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train.astype(np.float32)).to(device)\n",
    "X_test_tensor = torch.tensor(X_test.astype(np.float32)).to(device)\n",
    "y_train_tensor = torch.tensor(y_train.values.astype(np.float32)).to(device)\n",
    "y_test_tensor = torch.tensor(y_test.values.astype(np.float32)).to(device)\n",
    "\n",
    "# # Reshape y tensors to have the correct shape (n_samples, 1)\n",
    "y_train_tensor = y_train_tensor.view(-1, 1)\n",
    "y_test_tensor = y_test_tensor.view(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create datasets\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "def rmsle_loss(y_pred, y_true):\n",
    "    # Ensure the inputs are float tensors (required for MSELoss and logarithmic operations)\n",
    "\n",
    "    \n",
    "    # Compute the RMSLE using the logarithmic differences\n",
    "    return torch.sqrt(torch.mean((torch.log1p(y_pred) - torch.log1p(y_true)) ** 2))\n",
    "    # return torch.sqrt(torch.mean((y_pred - y_true) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import CyclicLR\n",
    "\n",
    "def train_model(model, train_loader, test_loader, num_epochs=5):\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-6, momentum=0.8)\n",
    "    scheduler = CyclicLR(optimizer, base_lr=1e-6, max_lr=0.1, step_size_up=5*len(train_loader),\n",
    "                     mode='triangular', cycle_momentum=False)\n",
    "\n",
    "\n",
    "    min_train_rmsle = float('inf')\n",
    "    min_test_rmsle = float('inf')\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = rmsle_loss(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()  # Update learning rate at each batch\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "        avg_train_rmsle = total_train_loss / len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        total_test_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in test_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                test_loss = rmsle_loss(outputs, targets)\n",
    "                total_test_loss += test_loss.item()\n",
    "\n",
    "        avg_test_rmsle = total_test_loss / len(test_loader)\n",
    "\n",
    "        if avg_train_rmsle < min_train_rmsle:\n",
    "            min_train_rmsle = avg_train_rmsle\n",
    "        if avg_test_rmsle < min_test_rmsle:\n",
    "            min_test_rmsle = avg_test_rmsle\n",
    "\n",
    "        print(f'Epoch {epoch+1}: Train RMSLE = {avg_train_rmsle}, Test RMSLE = {avg_test_rmsle} , Current LR = {scheduler.get_last_lr()}')\n",
    "\n",
    "    print(f'Minimum Train RMSLE so far: {min_train_rmsle}')\n",
    "    print(f'Minimum Test RMSLE so far: {min_test_rmsle}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_model(model, train_loader, test_loader, num_epochs=5):\n",
    "#     model.to(device)\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=0.02)\n",
    "#     scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=2, verbose=True, min_lr=1e-6)\n",
    "\n",
    "#     # Initialize minimum loss to a large value\n",
    "#     min_train_rmsle = float('inf')\n",
    "#     min_test_rmsle = float('inf')\n",
    "\n",
    "#     for epoch in range(num_epochs):\n",
    "#         model.train()\n",
    "#         total_train_loss = 0\n",
    "#         for inputs, targets in train_loader:\n",
    "#             inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "#             optimizer.zero_grad()\n",
    "#             outputs = model(inputs)\n",
    "#             loss = rmsle_loss(outputs, targets)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             total_train_loss += loss.item()\n",
    "\n",
    "#         avg_train_rmsle = total_train_loss / len(train_loader)\n",
    "\n",
    "#         model.eval()\n",
    "#         total_test_loss = 0\n",
    "#         with torch.no_grad():\n",
    "#             for inputs, targets in test_loader:\n",
    "#                 inputs, targets = inputs.to(device), targets.to(device)\n",
    "#                 outputs = model(inputs)\n",
    "#                 test_loss = rmsle_loss(outputs, targets)\n",
    "#                 total_test_loss += test_loss.item()\n",
    "\n",
    "#         avg_test_rmsle = total_test_loss / len(test_loader)\n",
    "        \n",
    "#         # Update the learning rate scheduler\n",
    "#         scheduler.step(avg_test_rmsle)\n",
    "\n",
    "#         if avg_train_rmsle < min_train_rmsle:\n",
    "#             min_train_rmsle = avg_train_rmsle\n",
    "#         if avg_test_rmsle < min_test_rmsle:\n",
    "#             min_test_rmsle = avg_test_rmsle\n",
    "\n",
    "#         print(f'Epoch {epoch+1}: Train RMSLE = {avg_train_rmsle}, Test RMSLE = {avg_test_rmsle} , {scheduler.get_last_lr()}')\n",
    "    \n",
    "#     print(f'Minimum Train RMSLE so far: {min_train_rmsle}')\n",
    "#     print(f'Minimum Test RMSLE so far: {min_test_rmsle}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = X_train.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AdvancedMLP(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(AdvancedMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(num_features, 1024)\n",
    "        self.bn1 = nn.BatchNorm1d(1024)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.bn2 = nn.BatchNorm1d(512)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        self.dropout3 = nn.Dropout(0.1)\n",
    "        \n",
    "        self.fc4 = nn.Linear(256, 128)\n",
    "        self.bn4 = nn.BatchNorm1d(128)\n",
    "        \n",
    "        self.final_layer = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.leaky_relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout2(x)\n",
    "        x = F.leaky_relu(self.bn3(self.fc3(x)))\n",
    "        x = self.dropout3(x)\n",
    "        x = F.leaky_relu(self.bn4(self.fc4(x)))\n",
    "        x = self.final_layer(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train RMSLE = 0.7514917956175907, Test RMSLE = 0.691889699742976 , Current LR = [0.020080000000000018]\n",
      "Epoch 2: Train RMSLE = 0.6929407155532386, Test RMSLE = 0.6899763355093947 , Current LR = [0.04006]\n",
      "Epoch 3: Train RMSLE = 0.6914681243433587, Test RMSLE = 0.6898108521099869 , Current LR = [0.06004000000000001]\n",
      "Epoch 4: Train RMSLE = 0.6908821830577122, Test RMSLE = 0.6894941653712208 , Current LR = [0.08002]\n",
      "Epoch 5: Train RMSLE = 0.6907152118919099, Test RMSLE = 0.6900911300057867 , Current LR = [0.1]\n",
      "Epoch 6: Train RMSLE = 0.6903489363416979, Test RMSLE = 0.6894711216729648 , Current LR = [0.08002]\n",
      "Epoch 7: Train RMSLE = 0.689899885309937, Test RMSLE = 0.6891402827807699 , Current LR = [0.06004000000000001]\n",
      "Epoch 8: Train RMSLE = 0.6895308730073392, Test RMSLE = 0.6893058754753077 , Current LR = [0.04006]\n",
      "Epoch 9: Train RMSLE = 0.6890082106383297, Test RMSLE = 0.6892872435780095 , Current LR = [0.020080000000000018]\n",
      "Epoch 10: Train RMSLE = 0.688635042431471, Test RMSLE = 0.6890960018159236 , Current LR = [0.0001]\n",
      "Minimum Train RMSLE so far: 0.688635042431471\n",
      "Minimum Test RMSLE so far: 0.6890960018159236\n"
     ]
    }
   ],
   "source": [
    "model = AdvancedMLP(num_features).to(device)\n",
    "train_model(model, train_loader, test_loader, num_epochs=10)\n",
    "# Minimum Train RMSLE so far: 0.6773702232499507\n",
    "# Minimum Test RMSLE so far: 0.678769255297098"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CustomMLP(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(CustomMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(num_features, 1024)\n",
    "        self.bn1 = nn.BatchNorm1d(1024)\n",
    "        \n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.fc4 = nn.Linear(256, 128)\n",
    "        self.fc5 = nn.Linear(128, 64)\n",
    "        self.fc6 = nn.Linear(64, 32)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "        self.final_layer = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.bn1(x)\n",
    "        \n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = F.relu(self.fc6(x))\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        x = self.final_layer(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model10 = CustomMLP(num_features).to(device)\n",
    "train_model(model10, train_loader, test_loader, num_epochs=10)\n",
    "\n",
    "# Minimum Train RMSLE so far: 0.6754996292528404\n",
    "# Minimum Test RMSLE so far: 0.6798468978210392"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DynamicMLP(nn.Module):\n",
    "    def __init__(self, num_features, max_first_layer_size, min_layer_size=32, output_size=1):\n",
    "        super(DynamicMLP, self).__init__()\n",
    "        layers = []\n",
    "        current_size = max_first_layer_size\n",
    "        # Ensure the loop creates layers correctly by adjusting input and output sizes\n",
    "        input_size = num_features  # Starting number of features\n",
    "        while current_size > min_layer_size:\n",
    "            next_size = max(current_size // 2, min_layer_size)\n",
    "            layers.append(nn.Linear(input_size, current_size))\n",
    "            layers.append(nn.BatchNorm1d(current_size))\n",
    "            # layers.append(nn.Dropout(0.05))  # Using a constant dropout rate\n",
    "            layers.append(nn.ReLU())\n",
    "            input_size = current_size  # Update input size for the next layer\n",
    "            current_size = next_size\n",
    "        \n",
    "        # Append the final layer\n",
    "        layers.append(nn.Linear(input_size, output_size))\n",
    "\n",
    "        # Register all layers\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "# Example of using the DynamicMLP class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DynamicMLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=48, out_features=1024, bias=True)\n",
      "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (7): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU()\n",
      "    (9): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (10): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): ReLU()\n",
      "    (12): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (13): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): ReLU()\n",
      "    (15): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "max_first_layer_size = 1024  # Adjusted for demonstration\n",
    "model = DynamicMLP(num_features, max_first_layer_size).to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train RMSLE = 0.7755220616465888, Test RMSLE = 0.6898555177126824 , Current LR = [0.02000080000000002]\n",
      "Epoch 2: Train RMSLE = 0.6901063022337403, Test RMSLE = 0.6879812699859111 , Current LR = [0.0400006]\n",
      "Epoch 3: Train RMSLE = 0.6891731141734524, Test RMSLE = 0.6884494067505054 , Current LR = [0.06000040000000001]\n",
      "Epoch 4: Train RMSLE = 0.6888162409863118, Test RMSLE = 0.6885505358649272 , Current LR = [0.0800002]\n",
      "Epoch 5: Train RMSLE = 0.6884706852808715, Test RMSLE = 0.6893075191993177 , Current LR = [0.1]\n",
      "Epoch 6: Train RMSLE = 0.6880786281454072, Test RMSLE = 0.6883744412637943 , Current LR = [0.0800002]\n",
      "Epoch 7: Train RMSLE = 0.6871726254996301, Test RMSLE = 0.6887541645783841 , Current LR = [0.06000040000000001]\n",
      "Epoch 8: Train RMSLE = 0.6861238504724139, Test RMSLE = 0.6883898411504795 , Current LR = [0.0400006]\n",
      "Epoch 9: Train RMSLE = 0.6847569100117662, Test RMSLE = 0.6892120573867908 , Current LR = [0.02000080000000002]\n",
      "Epoch 10: Train RMSLE = 0.6827360125809078, Test RMSLE = 0.6899582764395122 , Current LR = [1e-06]\n",
      "Minimum Train RMSLE so far: 0.6827360125809078\n",
      "Minimum Test RMSLE so far: 0.6879812699859111\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_loader, test_loader, num_epochs=10)\n",
    "# Minimum Train RMSLE so far: 0.6845218561584729\n",
    "# Minimum Test RMSLE so far: 0.6898618382582543"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XG BOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# Assume `train` is your DataFrame loaded with the data\n",
    "X = train.drop(columns=['price'])\n",
    "y = np.log1p(train['price'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    # prevent negative predictions\n",
    "    preds = np.clip(preds, a_min=0, a_max=None)\n",
    "    return 'RMSLE', np.sqrt(np.mean(np.power((preds-labels), 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "[CV 1/3] END colsample_bytree=0.8674996517121547, learning_rate=0.08997993265440231, max_depth=10, min_child_weight=87, n_estimators=372, subsample=0.9606690070459252;, score=-0.696 total time= 1.4min\n",
      "[CV 2/3] END colsample_bytree=0.8247240713084174, learning_rate=0.770571445127933, max_depth=10, min_child_weight=71, n_estimators=700, subsample=0.9581100947678922;, score=-0.870 total time= 2.7min\n",
      "[CV 1/3] END colsample_bytree=0.8247240713084174, learning_rate=0.770571445127933, max_depth=10, min_child_weight=71, n_estimators=700, subsample=0.9581100947678922;, score=-0.871 total time= 2.7min\n",
      "[CV 3/3] END colsample_bytree=0.8247240713084174, learning_rate=0.770571445127933, max_depth=10, min_child_weight=71, n_estimators=700, subsample=0.9581100947678922;, score=-0.870 total time= 2.7min\n",
      "[CV 1/3] END colsample_bytree=1.0248435466776273, learning_rate=0.026467595436641955, max_depth=1, min_child_weight=87, n_estimators=491, subsample=1.16313162540945;, score=nan total time=   2.7s\n",
      "[CV 2/3] END colsample_bytree=0.8674996517121547, learning_rate=0.08997993265440231, max_depth=10, min_child_weight=87, n_estimators=372, subsample=0.9606690070459252;, score=-0.695 total time= 1.4min\n",
      "[CV 2/3] END colsample_bytree=1.0248435466776273, learning_rate=0.026467595436641955, max_depth=1, min_child_weight=87, n_estimators=491, subsample=1.16313162540945;, score=nan total time=   3.3s\n",
      "[CV 3/3] END colsample_bytree=1.0248435466776273, learning_rate=0.026467595436641955, max_depth=1, min_child_weight=87, n_estimators=491, subsample=1.16313162540945;, score=nan total time=   3.3s\n",
      "[CV 3/3] END colsample_bytree=0.8674996517121547, learning_rate=0.08997993265440231, max_depth=10, min_child_weight=87, n_estimators=372, subsample=0.9606690070459252;, score=-0.697 total time= 1.7min\n",
      "[CV 1/3] END colsample_bytree=0.8591670111852694, learning_rate=0.24298331215843355, max_depth=26, min_child_weight=41, n_estimators=475, subsample=1.1842533113048754;, score=nan total time=   5.9s\n",
      "[CV 2/3] END colsample_bytree=0.8591670111852694, learning_rate=0.24298331215843355, max_depth=26, min_child_weight=41, n_estimators=475, subsample=1.1842533113048754;, score=nan total time=   6.2s\n",
      "[CV 3/3] END colsample_bytree=0.8591670111852694, learning_rate=0.24298331215843355, max_depth=26, min_child_weight=41, n_estimators=475, subsample=1.1842533113048754;, score=nan total time=   5.0s\n",
      "[CV 2/3] END colsample_bytree=0.6004672595046086, learning_rate=0.8037692474329741, max_depth=0, min_child_weight=75, n_estimators=313, subsample=0.9148538589793427;, score=-0.920 total time=10.8min\n",
      "[CV 1/3] END colsample_bytree=0.6004672595046086, learning_rate=0.8037692474329741, max_depth=0, min_child_weight=75, n_estimators=313, subsample=0.9148538589793427;, score=-0.920 total time=10.8min\n",
      "[CV 3/3] END colsample_bytree=0.6004672595046086, learning_rate=0.8037692474329741, max_depth=0, min_child_weight=75, n_estimators=313, subsample=0.9148538589793427;, score=-0.918 total time=10.8min\n",
      "[CV 1/3] END colsample_bytree=0.9554487413172255, learning_rate=0.04716033017599818, max_depth=18, min_child_weight=6, n_estimators=20, subsample=0.8702995511817258;, score=-0.702 total time= 4.8min\n",
      "[CV 2/3] END colsample_bytree=0.9554487413172255, learning_rate=0.04716033017599818, max_depth=18, min_child_weight=6, n_estimators=20, subsample=0.8702995511817258;, score=-0.701 total time= 4.5min\n",
      "[CV 3/3] END colsample_bytree=0.9554487413172255, learning_rate=0.04716033017599818, max_depth=18, min_child_weight=6, n_estimators=20, subsample=0.8702995511817258;, score=-0.703 total time= 5.4min\n",
      "[CV 1/3] END colsample_bytree=0.6079589766959199, learning_rate=0.7637614045478822, max_depth=13, min_child_weight=8, n_estimators=345, subsample=0.6586032684038303;, score=-1.033 total time= 3.7min\n",
      "[CV 2/3] END colsample_bytree=0.6079589766959199, learning_rate=0.7637614045478822, max_depth=13, min_child_weight=8, n_estimators=345, subsample=0.6586032684038303;, score=-1.031 total time= 3.9min\n",
      "[CV 1/3] END colsample_bytree=0.7396628042581825, learning_rate=0.08248514762625664, max_depth=29, min_child_weight=50, n_estimators=875, subsample=0.9085406630481669;, score=-0.709 total time=32.9min\n",
      "[CV 1/3] END colsample_bytree=1.010539815907294, learning_rate=0.3621219949916811, max_depth=6, min_child_weight=43, n_estimators=508, subsample=1.0999169470416985;, score=nan total time=   4.7s\n",
      "[CV 2/3] END colsample_bytree=1.010539815907294, learning_rate=0.3621219949916811, max_depth=6, min_child_weight=43, n_estimators=508, subsample=1.0999169470416985;, score=nan total time=   4.4s\n",
      "[CV 3/3] END colsample_bytree=1.010539815907294, learning_rate=0.3621219949916811, max_depth=6, min_child_weight=43, n_estimators=508, subsample=1.0999169470416985;, score=nan total time=   4.4s\n",
      "[CV 1/3] END colsample_bytree=0.7040187921046632, learning_rate=0.3228484860585927, max_depth=17, min_child_weight=3, n_estimators=1, subsample=0.8550935246947469;, score=-0.730 total time=  14.6s\n",
      "[CV 2/3] END colsample_bytree=0.7040187921046632, learning_rate=0.3228484860585927, max_depth=17, min_child_weight=3, n_estimators=1, subsample=0.8550935246947469;, score=-0.728 total time=  14.5s\n",
      "[CV 3/3] END colsample_bytree=0.7040187921046632, learning_rate=0.3228484860585927, max_depth=17, min_child_weight=3, n_estimators=1, subsample=0.8550935246947469;, score=-0.731 total time=  15.4s\n",
      "[CV 1/3] END colsample_bytree=0.7247649977209133, learning_rate=0.4641602622559932, max_depth=28, min_child_weight=62, n_estimators=401, subsample=1.0650796940166687;, score=nan total time=   4.5s\n",
      "[CV 2/3] END colsample_bytree=0.7247649977209133, learning_rate=0.4641602622559932, max_depth=28, min_child_weight=62, n_estimators=401, subsample=1.0650796940166687;, score=nan total time=   4.4s\n",
      "[CV 3/3] END colsample_bytree=0.7247649977209133, learning_rate=0.4641602622559932, max_depth=28, min_child_weight=62, n_estimators=401, subsample=1.0650796940166687;, score=nan total time=   4.5s\n",
      "[CV 1/3] END colsample_bytree=1.1636993649385134, learning_rate=0.7258618803421191, max_depth=13, min_child_weight=94, n_estimators=815, subsample=0.7959244612835013;, score=nan total time=   4.2s\n",
      "[CV 2/3] END colsample_bytree=1.1636993649385134, learning_rate=0.7258618803421191, max_depth=13, min_child_weight=94, n_estimators=815, subsample=0.7959244612835013;, score=nan total time=   4.4s\n",
      "[CV 3/3] END colsample_bytree=1.1636993649385134, learning_rate=0.7258618803421191, max_depth=13, min_child_weight=94, n_estimators=815, subsample=0.7959244612835013;, score=nan total time=   4.3s\n",
      "[CV 3/3] END colsample_bytree=0.6079589766959199, learning_rate=0.7637614045478822, max_depth=13, min_child_weight=8, n_estimators=345, subsample=0.6586032684038303;, score=-1.028 total time= 3.7min\n",
      "[CV 2/3] END colsample_bytree=0.7396628042581825, learning_rate=0.08248514762625664, max_depth=29, min_child_weight=50, n_estimators=875, subsample=0.9085406630481669;, score=-0.708 total time=40.2min\n",
      "[CV 3/3] END colsample_bytree=0.7396628042581825, learning_rate=0.08248514762625664, max_depth=29, min_child_weight=50, n_estimators=875, subsample=0.9085406630481669;, score=-0.710 total time=43.7min\n",
      "[CV 1/3] END colsample_bytree=0.9422663846432395, learning_rate=0.42666740802065894, max_depth=29, min_child_weight=39, n_estimators=724, subsample=0.8332063738136892;, score=-0.798 total time=30.8min\n",
      "[CV 1/3] END colsample_bytree=0.7628094190643375, learning_rate=0.6729900073215436, max_depth=25, min_child_weight=88, n_estimators=763, subsample=0.9642205486120108;, score=-0.854 total time=13.1min\n",
      "[CV 2/3] END colsample_bytree=0.9422663846432395, learning_rate=0.42666740802065894, max_depth=29, min_child_weight=39, n_estimators=724, subsample=0.8332063738136892;, score=-0.798 total time=31.4min\n",
      "[CV 1/3] END colsample_bytree=0.7655995092135259, learning_rate=0.24701880456326594, max_depth=12, min_child_weight=64, n_estimators=856, subsample=1.1921321619603105;, score=nan total time=   4.7s\n",
      "[CV 2/3] END colsample_bytree=0.7655995092135259, learning_rate=0.24701880456326594, max_depth=12, min_child_weight=64, n_estimators=856, subsample=1.1921321619603105;, score=nan total time=   4.4s\n",
      "[CV 3/3] END colsample_bytree=0.7655995092135259, learning_rate=0.24701880456326594, max_depth=12, min_child_weight=64, n_estimators=856, subsample=1.1921321619603105;, score=nan total time=   4.5s\n",
      "[CV 1/3] END colsample_bytree=1.0633468615779944, learning_rate=0.16897254522733796, max_depth=23, min_child_weight=62, n_estimators=138, subsample=0.7193054424532831;, score=nan total time=   4.6s\n",
      "[CV 2/3] END colsample_bytree=1.0633468615779944, learning_rate=0.16897254522733796, max_depth=23, min_child_weight=62, n_estimators=138, subsample=0.7193054424532831;, score=nan total time=   4.1s\n",
      "[CV 3/3] END colsample_bytree=1.0633468615779944, learning_rate=0.16897254522733796, max_depth=23, min_child_weight=62, n_estimators=138, subsample=0.7193054424532831;, score=nan total time=   4.1s\n",
      "[CV 1/3] END colsample_bytree=1.02680517164919, learning_rate=0.6421404324249645, max_depth=26, min_child_weight=4, n_estimators=489, subsample=0.8150794371265635;, score=nan total time=   4.2s\n",
      "[CV 2/3] END colsample_bytree=1.02680517164919, learning_rate=0.6421404324249645, max_depth=26, min_child_weight=4, n_estimators=489, subsample=0.8150794371265635;, score=nan total time=   4.2s\n",
      "[CV 3/3] END colsample_bytree=1.02680517164919, learning_rate=0.6421404324249645, max_depth=26, min_child_weight=4, n_estimators=489, subsample=0.8150794371265635;, score=nan total time=   4.2s\n",
      "[CV 3/3] END colsample_bytree=0.9422663846432395, learning_rate=0.42666740802065894, max_depth=29, min_child_weight=39, n_estimators=724, subsample=0.8332063738136892;, score=-0.800 total time=19.9min\n",
      "[CV 1/3] END colsample_bytree=0.6695214357150778, learning_rate=0.7004827407004749, max_depth=7, min_child_weight=11, n_estimators=929, subsample=0.6572460698942467;, score=-0.845 total time= 3.1min\n",
      "[CV 2/3] END colsample_bytree=0.6695214357150778, learning_rate=0.7004827407004749, max_depth=7, min_child_weight=11, n_estimators=929, subsample=0.6572460698942467;, score=-0.845 total time= 2.8min\n",
      "[CV 3/3] END colsample_bytree=0.6695214357150778, learning_rate=0.7004827407004749, max_depth=7, min_child_weight=11, n_estimators=929, subsample=0.6572460698942467;, score=-0.845 total time= 2.8min\n",
      "[CV 1/3] END colsample_bytree=0.8224909513189598, learning_rate=0.5450730021308858, max_depth=4, min_child_weight=98, n_estimators=683, subsample=0.9825344828131278;, score=-0.700 total time= 1.2min\n",
      "[CV 2/3] END colsample_bytree=0.8224909513189598, learning_rate=0.5450730021308858, max_depth=4, min_child_weight=98, n_estimators=683, subsample=0.9825344828131278;, score=-0.700 total time= 1.2min\n",
      "[CV 1/3] END colsample_bytree=1.132327645545796, learning_rate=0.38777194012955946, max_depth=4, min_child_weight=46, n_estimators=461, subsample=1.1093482945596502;, score=nan total time=   4.0s\n",
      "[CV 3/3] END colsample_bytree=0.8224909513189598, learning_rate=0.5450730021308858, max_depth=4, min_child_weight=98, n_estimators=683, subsample=0.9825344828131278;, score=-0.701 total time= 1.2min\n",
      "[CV 2/3] END colsample_bytree=1.132327645545796, learning_rate=0.38777194012955946, max_depth=4, min_child_weight=46, n_estimators=461, subsample=1.1093482945596502;, score=nan total time=   3.6s\n",
      "[CV 3/3] END colsample_bytree=1.132327645545796, learning_rate=0.38777194012955946, max_depth=4, min_child_weight=46, n_estimators=461, subsample=1.1093482945596502;, score=nan total time=   3.6s\n",
      "[CV 1/3] END colsample_bytree=1.0330377126989239, learning_rate=0.19878793579916462, max_depth=13, min_child_weight=26, n_estimators=392, subsample=1.0263977338114725;, score=nan total time=   3.5s\n",
      "[CV 2/3] END colsample_bytree=1.0330377126989239, learning_rate=0.19878793579916462, max_depth=13, min_child_weight=26, n_estimators=392, subsample=1.0263977338114725;, score=nan total time=   3.5s\n",
      "[CV 3/3] END colsample_bytree=1.0330377126989239, learning_rate=0.19878793579916462, max_depth=13, min_child_weight=26, n_estimators=392, subsample=1.0263977338114725;, score=nan total time=   3.6s\n",
      "[CV 2/3] END colsample_bytree=0.7628094190643375, learning_rate=0.6729900073215436, max_depth=25, min_child_weight=88, n_estimators=763, subsample=0.9642205486120108;, score=-0.854 total time=17.4min\n",
      "[CV 3/3] END colsample_bytree=0.7628094190643375, learning_rate=0.6729900073215436, max_depth=25, min_child_weight=88, n_estimators=763, subsample=0.9642205486120108;, score=-0.854 total time=17.3min\n",
      "[CV 1/3] END colsample_bytree=0.6665344924870987, learning_rate=0.36146920149261613, max_depth=18, min_child_weight=62, n_estimators=863, subsample=0.9818462467582683;, score=-0.766 total time=20.1min\n",
      "[CV 2/3] END colsample_bytree=0.6665344924870987, learning_rate=0.36146920149261613, max_depth=18, min_child_weight=62, n_estimators=863, subsample=0.9818462467582683;, score=-0.766 total time=20.1min\n",
      "[CV 3/3] END colsample_bytree=0.6665344924870987, learning_rate=0.36146920149261613, max_depth=18, min_child_weight=62, n_estimators=863, subsample=0.9818462467582683;, score=-0.766 total time=14.7min\n",
      "[CV 1/3] END colsample_bytree=1.0533306831258291, learning_rate=0.193038532393298, max_depth=6, min_child_weight=58, n_estimators=242, subsample=0.6967327723524026;, score=nan total time=   9.8s\n",
      "[CV 2/3] END colsample_bytree=1.0533306831258291, learning_rate=0.193038532393298, max_depth=6, min_child_weight=58, n_estimators=242, subsample=0.6967327723524026;, score=nan total time=   7.7s\n",
      "[CV 3/3] END colsample_bytree=1.0533306831258291, learning_rate=0.193038532393298, max_depth=6, min_child_weight=58, n_estimators=242, subsample=0.6967327723524026;, score=nan total time=   7.8s\n",
      "[CV 1/3] END colsample_bytree=0.788613588645796, learning_rate=0.41685655293176227, max_depth=29, min_child_weight=22, n_estimators=230, subsample=0.8462297538213778;, score=-0.794 total time=14.9min\n",
      "[CV 1/3] END colsample_bytree=1.1578185914055439, learning_rate=0.6564963036515337, max_depth=24, min_child_weight=5, n_estimators=795, subsample=1.0822032461394686;, score=nan total time=   8.5s\n",
      "[CV 2/3] END colsample_bytree=1.1578185914055439, learning_rate=0.6564963036515337, max_depth=24, min_child_weight=5, n_estimators=795, subsample=1.0822032461394686;, score=nan total time=   8.6s\n",
      "[CV 3/3] END colsample_bytree=1.1578185914055439, learning_rate=0.6564963036515337, max_depth=24, min_child_weight=5, n_estimators=795, subsample=1.0822032461394686;, score=nan total time=   9.3s\n",
      "[CV 1/3] END colsample_bytree=0.7119420353316215, learning_rate=0.7240471987919823, max_depth=10, min_child_weight=91, n_estimators=472, subsample=0.7908020849831183;, score=-0.866 total time= 2.5min\n",
      "[CV 2/3] END colsample_bytree=0.7119420353316215, learning_rate=0.7240471987919823, max_depth=10, min_child_weight=91, n_estimators=472, subsample=0.7908020849831183;, score=-0.868 total time= 2.5min\n",
      "[CV 3/3] END colsample_bytree=0.7119420353316215, learning_rate=0.7240471987919823, max_depth=10, min_child_weight=91, n_estimators=472, subsample=0.7908020849831183;, score=-0.867 total time= 2.7min\n",
      "[CV 1/3] END colsample_bytree=0.666031154716606, learning_rate=0.19234813003355336, max_depth=29, min_child_weight=76, n_estimators=744, subsample=0.7828687548948174;, score=-0.740 total time=18.0min\n",
      "[CV 2/3] END colsample_bytree=0.666031154716606, learning_rate=0.19234813003355336, max_depth=29, min_child_weight=76, n_estimators=744, subsample=0.7828687548948174;, score=-0.740 total time=17.6min\n",
      "[CV 1/3] END colsample_bytree=0.698793511885765, learning_rate=0.4372715355003536, max_depth=29, min_child_weight=36, n_estimators=224, subsample=0.6719192204002097;, score=-0.838 total time= 7.6min\n",
      "[CV 3/3] END colsample_bytree=0.666031154716606, learning_rate=0.19234813003355336, max_depth=29, min_child_weight=76, n_estimators=744, subsample=0.7828687548948174;, score=-0.741 total time=15.5min\n",
      "[CV 2/3] END colsample_bytree=0.698793511885765, learning_rate=0.4372715355003536, max_depth=29, min_child_weight=36, n_estimators=224, subsample=0.6719192204002097;, score=-0.839 total time=30.2min\n",
      "[CV 3/3] END colsample_bytree=0.788613588645796, learning_rate=0.41685655293176227, max_depth=29, min_child_weight=22, n_estimators=230, subsample=0.8462297538213778;, score=-0.795 total time=64.6min\n",
      "[CV 2/3] END colsample_bytree=0.788613588645796, learning_rate=0.41685655293176227, max_depth=29, min_child_weight=22, n_estimators=230, subsample=0.8462297538213778;, score=-0.793 total time=65.2min\n",
      "[CV 3/3] END colsample_bytree=0.698793511885765, learning_rate=0.4372715355003536, max_depth=29, min_child_weight=36, n_estimators=224, subsample=0.6719192204002097;, score=-0.839 total time=32.5min\n",
      "[CV 2/3] END colsample_bytree=0.8025691028421768, learning_rate=0.7643277631300154, max_depth=21, min_child_weight=31, n_estimators=607, subsample=0.9348612012104047;, score=-0.891 total time=12.4min\n",
      "[CV 1/3] END colsample_bytree=0.8025691028421768, learning_rate=0.7643277631300154, max_depth=21, min_child_weight=31, n_estimators=607, subsample=0.9348612012104047;, score=-0.892 total time=13.2min\n",
      "[CV 3/3] END colsample_bytree=0.8025691028421768, learning_rate=0.7643277631300154, max_depth=21, min_child_weight=31, n_estimators=607, subsample=0.9348612012104047;, score=-0.893 total time=12.5min\n",
      "[CV 1/3] END colsample_bytree=0.8983491035354312, learning_rate=0.2507026478534157, max_depth=16, min_child_weight=55, n_estimators=80, subsample=0.760068608565171;, score=-0.725 total time= 1.1min\n",
      "[CV 1/3] END colsample_bytree=0.8423017026348245, learning_rate=0.06191379768718525, max_depth=25, min_child_weight=51, n_estimators=267, subsample=0.7510693774952184;, score=-0.705 total time= 6.6min\n",
      "[CV 2/3] END colsample_bytree=0.8983491035354312, learning_rate=0.2507026478534157, max_depth=16, min_child_weight=55, n_estimators=80, subsample=0.760068608565171;, score=-0.724 total time=  59.3s\n",
      "[CV 3/3] END colsample_bytree=0.8983491035354312, learning_rate=0.2507026478534157, max_depth=16, min_child_weight=55, n_estimators=80, subsample=0.760068608565171;, score=-0.726 total time= 1.0min\n",
      "[CV 1/3] END colsample_bytree=1.1859689734995917, learning_rate=0.33882961065458506, max_depth=22, min_child_weight=95, n_estimators=224, subsample=0.9806108068208182;, score=nan total time=   5.6s\n",
      "[CV 2/3] END colsample_bytree=1.1859689734995917, learning_rate=0.33882961065458506, max_depth=22, min_child_weight=95, n_estimators=224, subsample=0.9806108068208182;, score=nan total time=   4.3s\n",
      "[CV 3/3] END colsample_bytree=1.1859689734995917, learning_rate=0.33882961065458506, max_depth=22, min_child_weight=95, n_estimators=224, subsample=0.9806108068208182;, score=nan total time=   3.8s\n",
      "[CV 1/3] END colsample_bytree=1.00842327093286, learning_rate=0.4347476666537091, max_depth=25, min_child_weight=31, n_estimators=709, subsample=0.7452331629069002;, score=nan total time=   4.1s\n",
      "[CV 2/3] END colsample_bytree=1.00842327093286, learning_rate=0.4347476666537091, max_depth=25, min_child_weight=31, n_estimators=709, subsample=0.7452331629069002;, score=nan total time=   4.1s\n",
      "[CV 3/3] END colsample_bytree=1.00842327093286, learning_rate=0.4347476666537091, max_depth=25, min_child_weight=31, n_estimators=709, subsample=0.7452331629069002;, score=nan total time=   4.0s\n",
      "[CV 1/3] END colsample_bytree=1.0032813284435271, learning_rate=0.6192956922629741, max_depth=26, min_child_weight=16, n_estimators=766, subsample=1.0818838538279376;, score=nan total time=   4.0s\n",
      "[CV 2/3] END colsample_bytree=1.0032813284435271, learning_rate=0.6192956922629741, max_depth=26, min_child_weight=16, n_estimators=766, subsample=1.0818838538279376;, score=nan total time=   3.9s\n",
      "[CV 3/3] END colsample_bytree=1.0032813284435271, learning_rate=0.6192956922629741, max_depth=26, min_child_weight=16, n_estimators=766, subsample=1.0818838538279376;, score=nan total time=   3.7s\n",
      "[CV 2/3] END colsample_bytree=0.8423017026348245, learning_rate=0.06191379768718525, max_depth=25, min_child_weight=51, n_estimators=267, subsample=0.7510693774952184;, score=-0.704 total time= 7.1min\n",
      "[CV 3/3] END colsample_bytree=0.8423017026348245, learning_rate=0.06191379768718525, max_depth=25, min_child_weight=51, n_estimators=267, subsample=0.7510693774952184;, score=-0.706 total time= 6.8min\n",
      "[CV 1/3] END colsample_bytree=1.1011814973535428, learning_rate=0.2666240519773887, max_depth=5, min_child_weight=79, n_estimators=348, subsample=1.1150152828882318;, score=nan total time=  10.6s\n",
      "[CV 2/3] END colsample_bytree=1.1011814973535428, learning_rate=0.2666240519773887, max_depth=5, min_child_weight=79, n_estimators=348, subsample=1.1150152828882318;, score=nan total time=  11.7s\n",
      "[CV 3/3] END colsample_bytree=1.1011814973535428, learning_rate=0.2666240519773887, max_depth=5, min_child_weight=79, n_estimators=348, subsample=1.1150152828882318;, score=nan total time=   7.0s\n",
      "[CV 1/3] END colsample_bytree=0.7955753431211308, learning_rate=0.18619283805243866, max_depth=25, min_child_weight=66, n_estimators=510, subsample=0.7358974651187628;, score=-0.741 total time= 9.8min\n",
      "[CV 2/3] END colsample_bytree=0.7955753431211308, learning_rate=0.18619283805243866, max_depth=25, min_child_weight=66, n_estimators=510, subsample=0.7358974651187628;, score=-0.741 total time=11.9min\n",
      "[CV 1/3] END colsample_bytree=0.8821803806676229, learning_rate=0.7967385127158744, max_depth=21, min_child_weight=10, n_estimators=510, subsample=0.6541738620326449;, score=-1.064 total time=27.9min\n",
      "[CV 2/3] END colsample_bytree=0.8821803806676229, learning_rate=0.7967385127158744, max_depth=21, min_child_weight=10, n_estimators=510, subsample=0.6541738620326449;, score=-1.065 total time=30.9min\n",
      "[CV 3/3] END colsample_bytree=0.8821803806676229, learning_rate=0.7967385127158744, max_depth=21, min_child_weight=10, n_estimators=510, subsample=0.6541738620326449;, score=-1.062 total time=30.0min\n",
      "[CV 3/3] END colsample_bytree=0.7955753431211308, learning_rate=0.18619283805243866, max_depth=25, min_child_weight=66, n_estimators=510, subsample=0.7358974651187628;, score=-0.742 total time=11.4min\n",
      "[CV 1/3] END colsample_bytree=1.1026260635443967, learning_rate=0.5505520936314247, max_depth=24, min_child_weight=88, n_estimators=945, subsample=1.1548161709671376;, score=nan total time=   6.1s\n",
      "[CV 2/3] END colsample_bytree=1.1026260635443967, learning_rate=0.5505520936314247, max_depth=24, min_child_weight=88, n_estimators=945, subsample=1.1548161709671376;, score=nan total time=   5.6s\n",
      "[CV 3/3] END colsample_bytree=1.1026260635443967, learning_rate=0.5505520936314247, max_depth=24, min_child_weight=88, n_estimators=945, subsample=1.1548161709671376;, score=nan total time=   5.2s\n",
      "[CV 1/3] END colsample_bytree=1.1264036120285885, learning_rate=0.2163533021721245, max_depth=27, min_child_weight=15, n_estimators=345, subsample=1.1893010059976614;, score=nan total time=   5.2s\n",
      "[CV 2/3] END colsample_bytree=1.1264036120285885, learning_rate=0.2163533021721245, max_depth=27, min_child_weight=15, n_estimators=345, subsample=1.1893010059976614;, score=nan total time=   5.8s\n",
      "[CV 3/3] END colsample_bytree=1.1264036120285885, learning_rate=0.2163533021721245, max_depth=27, min_child_weight=15, n_estimators=345, subsample=1.1893010059976614;, score=nan total time=   5.5s\n",
      "[CV 1/3] END colsample_bytree=0.9099815347626086, learning_rate=0.21866333986432723, max_depth=0, min_child_weight=47, n_estimators=253, subsample=1.138329454771996;, score=nan total time=   5.9s\n",
      "[CV 2/3] END colsample_bytree=0.9099815347626086, learning_rate=0.21866333986432723, max_depth=0, min_child_weight=47, n_estimators=253, subsample=1.138329454771996;, score=nan total time=   6.2s\n",
      "[CV 3/3] END colsample_bytree=0.9099815347626086, learning_rate=0.21866333986432723, max_depth=0, min_child_weight=47, n_estimators=253, subsample=1.138329454771996;, score=nan total time=   5.4s\n",
      "[CV 1/3] END colsample_bytree=1.1402508342979982, learning_rate=0.5164811658186144, max_depth=8, min_child_weight=98, n_estimators=658, subsample=1.0355734073221436;, score=nan total time=   6.1s\n",
      "[CV 2/3] END colsample_bytree=1.1402508342979982, learning_rate=0.5164811658186144, max_depth=8, min_child_weight=98, n_estimators=658, subsample=1.0355734073221436;, score=nan total time=   5.7s\n",
      "[CV 3/3] END colsample_bytree=1.1402508342979982, learning_rate=0.5164811658186144, max_depth=8, min_child_weight=98, n_estimators=658, subsample=1.0355734073221436;, score=nan total time=   6.2s\n",
      "[CV 1/3] END colsample_bytree=1.1382661559715461, learning_rate=0.7196691394120939, max_depth=23, min_child_weight=32, n_estimators=919, subsample=1.1105570692605076;, score=nan total time=   6.3s\n",
      "[CV 2/3] END colsample_bytree=1.1382661559715461, learning_rate=0.7196691394120939, max_depth=23, min_child_weight=32, n_estimators=919, subsample=1.1105570692605076;, score=nan total time=   5.6s\n",
      "[CV 3/3] END colsample_bytree=1.1382661559715461, learning_rate=0.7196691394120939, max_depth=23, min_child_weight=32, n_estimators=919, subsample=1.1105570692605076;, score=nan total time=   6.0s\n",
      "[CV 1/3] END colsample_bytree=1.1613809965325683, learning_rate=0.6382725208911549, max_depth=7, min_child_weight=83, n_estimators=253, subsample=0.6055182309699778;, score=nan total time=   5.9s\n",
      "[CV 2/3] END colsample_bytree=1.1613809965325683, learning_rate=0.6382725208911549, max_depth=7, min_child_weight=83, n_estimators=253, subsample=0.6055182309699778;, score=nan total time=   6.3s\n",
      "[CV 3/3] END colsample_bytree=1.1613809965325683, learning_rate=0.6382725208911549, max_depth=7, min_child_weight=83, n_estimators=253, subsample=0.6055182309699778;, score=nan total time=   6.0s\n",
      "[CV 1/3] END colsample_bytree=0.6608829257196193, learning_rate=0.5408014152864447, max_depth=28, min_child_weight=17, n_estimators=895, subsample=0.7832183162066361;, score=-0.849 total time=92.7min\n",
      "[CV 2/3] END colsample_bytree=0.6608829257196193, learning_rate=0.5408014152864447, max_depth=28, min_child_weight=17, n_estimators=895, subsample=0.7832183162066361;, score=-0.848 total time=54.6min\n",
      "[CV 3/3] END colsample_bytree=0.6608829257196193, learning_rate=0.5408014152864447, max_depth=28, min_child_weight=17, n_estimators=895, subsample=0.7832183162066361;, score=-0.849 total time=46.4min\n",
      "[CV 1/3] END colsample_bytree=0.8913682521517359, learning_rate=0.3687393143889979, max_depth=28, min_child_weight=40, n_estimators=995, subsample=1.0273075328085215;, score=nan total time=   9.4s\n",
      "[CV 2/3] END colsample_bytree=0.8913682521517359, learning_rate=0.3687393143889979, max_depth=28, min_child_weight=40, n_estimators=995, subsample=1.0273075328085215;, score=nan total time=   4.5s\n",
      "[CV 3/3] END colsample_bytree=0.8913682521517359, learning_rate=0.3687393143889979, max_depth=28, min_child_weight=40, n_estimators=995, subsample=1.0273075328085215;, score=nan total time=   5.0s\n",
      "[CV 1/3] END colsample_bytree=0.74234945249808, learning_rate=0.2703197585274142, max_depth=19, min_child_weight=7, n_estimators=134, subsample=1.0325639545512775;, score=nan total time=   4.6s\n",
      "[CV 2/3] END colsample_bytree=0.74234945249808, learning_rate=0.2703197585274142, max_depth=19, min_child_weight=7, n_estimators=134, subsample=1.0325639545512775;, score=nan total time=   4.1s\n",
      "[CV 3/3] END colsample_bytree=0.74234945249808, learning_rate=0.2703197585274142, max_depth=19, min_child_weight=7, n_estimators=134, subsample=1.0325639545512775;, score=nan total time=   4.6s\n",
      "[CV 1/3] END colsample_bytree=0.9871036742456698, learning_rate=0.14949314320399318, max_depth=0, min_child_weight=39, n_estimators=639, subsample=0.9106508103164881;, score=-0.723 total time=206.6min\n",
      "[CV 2/3] END colsample_bytree=0.9871036742456698, learning_rate=0.14949314320399318, max_depth=0, min_child_weight=39, n_estimators=639, subsample=0.9106508103164881;, score=-0.722 total time=209.4min\n",
      "[CV 3/3] END colsample_bytree=0.9871036742456698, learning_rate=0.14949314320399318, max_depth=0, min_child_weight=39, n_estimators=639, subsample=0.9106508103164881;, score=-0.724 total time=206.4min\n",
      "[CV 1/3] END colsample_bytree=0.7848364751114335, learning_rate=0.44403218444391945, max_depth=26, min_child_weight=85, n_estimators=374, subsample=0.7502770911633505;, score=-0.821 total time= 8.1min\n",
      "[CV 2/3] END colsample_bytree=0.7848364751114335, learning_rate=0.44403218444391945, max_depth=26, min_child_weight=85, n_estimators=374, subsample=0.7502770911633505;, score=-0.823 total time= 8.1min\n",
      "[CV 3/3] END colsample_bytree=0.7848364751114335, learning_rate=0.44403218444391945, max_depth=26, min_child_weight=85, n_estimators=374, subsample=0.7502770911633505;, score=-0.823 total time= 7.0min\n",
      "[CV 1/3] END colsample_bytree=1.076886782124989, learning_rate=0.4121096744841537, max_depth=27, min_child_weight=63, n_estimators=480, subsample=0.7171457926788267;, score=nan total time=   4.3s\n",
      "[CV 2/3] END colsample_bytree=1.076886782124989, learning_rate=0.4121096744841537, max_depth=27, min_child_weight=63, n_estimators=480, subsample=0.7171457926788267;, score=nan total time=   4.1s\n",
      "[CV 3/3] END colsample_bytree=1.076886782124989, learning_rate=0.4121096744841537, max_depth=27, min_child_weight=63, n_estimators=480, subsample=0.7171457926788267;, score=nan total time=   4.2s\n",
      "[CV 1/3] END colsample_bytree=1.0334712691569032, learning_rate=0.23461788995268465, max_depth=2, min_child_weight=63, n_estimators=48, subsample=0.6261622630526602;, score=nan total time=   3.9s\n",
      "[CV 2/3] END colsample_bytree=1.0334712691569032, learning_rate=0.23461788995268465, max_depth=2, min_child_weight=63, n_estimators=48, subsample=0.6261622630526602;, score=nan total time=   3.9s\n",
      "[CV 3/3] END colsample_bytree=1.0334712691569032, learning_rate=0.23461788995268465, max_depth=2, min_child_weight=63, n_estimators=48, subsample=0.6261622630526602;, score=nan total time=   3.9s\n",
      "[CV 1/3] END colsample_bytree=1.1967303064784045, learning_rate=0.3859556111927544, max_depth=13, min_child_weight=5, n_estimators=98, subsample=1.0486312643384483;, score=nan total time=   3.9s\n",
      "[CV 2/3] END colsample_bytree=1.1967303064784045, learning_rate=0.3859556111927544, max_depth=13, min_child_weight=5, n_estimators=98, subsample=1.0486312643384483;, score=nan total time=   4.3s\n",
      "[CV 3/3] END colsample_bytree=1.1967303064784045, learning_rate=0.3859556111927544, max_depth=13, min_child_weight=5, n_estimators=98, subsample=1.0486312643384483;, score=nan total time=   3.9s\n",
      "[CV 1/3] END colsample_bytree=1.1718431082143719, learning_rate=0.27460024373641095, max_depth=13, min_child_weight=52, n_estimators=606, subsample=1.1781719862535516;, score=nan total time=   4.0s\n",
      "[CV 2/3] END colsample_bytree=1.1718431082143719, learning_rate=0.27460024373641095, max_depth=13, min_child_weight=52, n_estimators=606, subsample=1.1781719862535516;, score=nan total time=   4.0s\n",
      "[CV 3/3] END colsample_bytree=1.1718431082143719, learning_rate=0.27460024373641095, max_depth=13, min_child_weight=52, n_estimators=606, subsample=1.1781719862535516;, score=nan total time=   4.0s\n",
      "[CV 1/3] END colsample_bytree=1.111805673280416, learning_rate=0.24555911365566857, max_depth=20, min_child_weight=31, n_estimators=982, subsample=0.7610849141340941;, score=nan total time=   4.0s\n",
      "[CV 2/3] END colsample_bytree=1.111805673280416, learning_rate=0.24555911365566857, max_depth=20, min_child_weight=31, n_estimators=982, subsample=0.7610849141340941;, score=nan total time=   3.9s\n",
      "[CV 3/3] END colsample_bytree=1.111805673280416, learning_rate=0.24555911365566857, max_depth=20, min_child_weight=31, n_estimators=982, subsample=0.7610849141340941;, score=nan total time=   4.0s\n",
      "[CV 1/3] END colsample_bytree=0.8911679245657893, learning_rate=0.30814949367523947, max_depth=9, min_child_weight=94, n_estimators=565, subsample=1.0176178780049838;, score=nan total time=   3.9s\n",
      "[CV 2/3] END colsample_bytree=0.8911679245657893, learning_rate=0.30814949367523947, max_depth=9, min_child_weight=94, n_estimators=565, subsample=1.0176178780049838;, score=nan total time=   3.9s\n",
      "[CV 3/3] END colsample_bytree=0.8911679245657893, learning_rate=0.30814949367523947, max_depth=9, min_child_weight=94, n_estimators=565, subsample=1.0176178780049838;, score=nan total time=   3.9s\n",
      "[CV 1/3] END colsample_bytree=0.9539225085363263, learning_rate=0.7931142866200073, max_depth=18, min_child_weight=53, n_estimators=775, subsample=0.9786831755983577;, score=-0.892 total time= 9.9min\n",
      "[CV 3/3] END colsample_bytree=0.9539225085363263, learning_rate=0.7931142866200073, max_depth=18, min_child_weight=53, n_estimators=775, subsample=0.9786831755983577;, score=-0.891 total time= 9.5min\n",
      "[CV 2/3] END colsample_bytree=0.9539225085363263, learning_rate=0.7931142866200073, max_depth=18, min_child_weight=53, n_estimators=775, subsample=0.9786831755983577;, score=-0.889 total time= 9.6min\n",
      "[CV 1/3] END colsample_bytree=0.910997791418242, learning_rate=0.7118984575423644, max_depth=16, min_child_weight=32, n_estimators=392, subsample=1.0214904503922655;, score=nan total time=   3.4s\n",
      "[CV 2/3] END colsample_bytree=0.910997791418242, learning_rate=0.7118984575423644, max_depth=16, min_child_weight=32, n_estimators=392, subsample=1.0214904503922655;, score=nan total time=   4.0s\n",
      "[CV 3/3] END colsample_bytree=0.910997791418242, learning_rate=0.7118984575423644, max_depth=16, min_child_weight=32, n_estimators=392, subsample=1.0214904503922655;, score=nan total time=   3.8s\n",
      "[CV 1/3] END colsample_bytree=0.9420367020536189, learning_rate=0.08774119501661483, max_depth=14, min_child_weight=85, n_estimators=662, subsample=0.6840504091419144;, score=-0.710 total time= 4.7min\n",
      "[CV 2/3] END colsample_bytree=0.9420367020536189, learning_rate=0.08774119501661483, max_depth=14, min_child_weight=85, n_estimators=662, subsample=0.6840504091419144;, score=-0.710 total time= 4.9min\n",
      "[CV 3/3] END colsample_bytree=0.9420367020536189, learning_rate=0.08774119501661483, max_depth=14, min_child_weight=85, n_estimators=662, subsample=0.6840504091419144;, score=-0.711 total time= 5.1min\n",
      "[CV 1/3] END colsample_bytree=0.9669082265194082, learning_rate=0.07527534432019228, max_depth=6, min_child_weight=56, n_estimators=35, subsample=1.078977107380065;, score=nan total time=   5.6s\n",
      "[CV 2/3] END colsample_bytree=0.9669082265194082, learning_rate=0.07527534432019228, max_depth=6, min_child_weight=56, n_estimators=35, subsample=1.078977107380065;, score=nan total time=   5.7s\n",
      "[CV 3/3] END colsample_bytree=0.9669082265194082, learning_rate=0.07527534432019228, max_depth=6, min_child_weight=56, n_estimators=35, subsample=1.078977107380065;, score=nan total time=   5.6s\n",
      "[CV 1/3] END colsample_bytree=0.989978358466659, learning_rate=0.5715735018061627, max_depth=15, min_child_weight=13, n_estimators=971, subsample=1.131970289370396;, score=nan total time=   5.8s\n",
      "[CV 2/3] END colsample_bytree=0.989978358466659, learning_rate=0.5715735018061627, max_depth=15, min_child_weight=13, n_estimators=971, subsample=1.131970289370396;, score=nan total time=   5.0s\n",
      "[CV 3/3] END colsample_bytree=0.989978358466659, learning_rate=0.5715735018061627, max_depth=15, min_child_weight=13, n_estimators=971, subsample=1.131970289370396;, score=nan total time=   4.6s\n",
      "[CV 1/3] END colsample_bytree=0.6165700631242228, learning_rate=0.473091916406047, max_depth=22, min_child_weight=62, n_estimators=853, subsample=0.7968916004848391;, score=-0.824 total time=13.5min\n",
      "[CV 1/3] END colsample_bytree=0.8156946907318531, learning_rate=0.2448734754115947, max_depth=22, min_child_weight=25, n_estimators=866, subsample=0.7537241661566748;, score=-0.755 total time=19.7min\n",
      "[CV 2/3] END colsample_bytree=0.8156946907318531, learning_rate=0.2448734754115947, max_depth=22, min_child_weight=25, n_estimators=866, subsample=0.7537241661566748;, score=-0.755 total time=20.7min\n",
      "[CV 3/3] END colsample_bytree=0.8156946907318531, learning_rate=0.2448734754115947, max_depth=22, min_child_weight=25, n_estimators=866, subsample=0.7537241661566748;, score=-0.756 total time=20.2min\n",
      "[CV 1/3] END colsample_bytree=0.6930249700366465, learning_rate=0.795472710648425, max_depth=21, min_child_weight=57, n_estimators=569, subsample=0.6183001499634296;, score=-1.140 total time= 8.6min\n",
      "[CV 2/3] END colsample_bytree=0.6930249700366465, learning_rate=0.795472710648425, max_depth=21, min_child_weight=57, n_estimators=569, subsample=0.6183001499634296;, score=-1.141 total time= 8.6min\n",
      "[CV 2/3] END colsample_bytree=0.6165700631242228, learning_rate=0.473091916406047, max_depth=22, min_child_weight=62, n_estimators=853, subsample=0.7968916004848391;, score=-0.822 total time=12.7min\n",
      "[CV 3/3] END colsample_bytree=0.6165700631242228, learning_rate=0.473091916406047, max_depth=22, min_child_weight=62, n_estimators=853, subsample=0.7968916004848391;, score=-0.823 total time=12.8min\n",
      "[CV 3/3] END colsample_bytree=0.6930249700366465, learning_rate=0.795472710648425, max_depth=21, min_child_weight=57, n_estimators=569, subsample=0.6183001499634296;, score=-1.141 total time= 8.9min\n",
      "[CV 1/3] END colsample_bytree=1.0619961318591664, learning_rate=0.18265682199747457, max_depth=4, min_child_weight=67, n_estimators=773, subsample=0.6310090327011646;, score=nan total time=   4.4s\n",
      "[CV 2/3] END colsample_bytree=1.0619961318591664, learning_rate=0.18265682199747457, max_depth=4, min_child_weight=67, n_estimators=773, subsample=0.6310090327011646;, score=nan total time=   4.3s\n",
      "[CV 3/3] END colsample_bytree=1.0619961318591664, learning_rate=0.18265682199747457, max_depth=4, min_child_weight=67, n_estimators=773, subsample=0.6310090327011646;, score=nan total time=   4.4s\n",
      "[CV 1/3] END colsample_bytree=0.6224089132495286, learning_rate=0.6680804485277266, max_depth=21, min_child_weight=59, n_estimators=612, subsample=0.9133459560328826;, score=-0.866 total time= 9.3min\n",
      "[CV 2/3] END colsample_bytree=0.6224089132495286, learning_rate=0.6680804485277266, max_depth=21, min_child_weight=59, n_estimators=612, subsample=0.9133459560328826;, score=-0.864 total time= 9.4min\n",
      "[CV 3/3] END colsample_bytree=0.6224089132495286, learning_rate=0.6680804485277266, max_depth=21, min_child_weight=59, n_estimators=612, subsample=0.9133459560328826;, score=-0.866 total time= 9.4min\n",
      "[CV 1/3] END colsample_bytree=1.1817221202684953, learning_rate=0.5816760833439617, max_depth=18, min_child_weight=16, n_estimators=119, subsample=0.7624993507572445;, score=nan total time=   4.5s\n",
      "[CV 2/3] END colsample_bytree=1.1817221202684953, learning_rate=0.5816760833439617, max_depth=18, min_child_weight=16, n_estimators=119, subsample=0.7624993507572445;, score=nan total time=   4.5s\n",
      "[CV 3/3] END colsample_bytree=1.1817221202684953, learning_rate=0.5816760833439617, max_depth=18, min_child_weight=16, n_estimators=119, subsample=0.7624993507572445;, score=nan total time=   4.2s\n",
      "[CV 1/3] END colsample_bytree=0.8633828524233816, learning_rate=0.07276510507381276, max_depth=4, min_child_weight=89, n_estimators=116, subsample=0.6485237799703186;, score=-0.692 total time=  18.8s\n",
      "[CV 2/3] END colsample_bytree=0.8633828524233816, learning_rate=0.07276510507381276, max_depth=4, min_child_weight=89, n_estimators=116, subsample=0.6485237799703186;, score=-0.691 total time=  18.7s\n",
      "[CV 3/3] END colsample_bytree=0.8633828524233816, learning_rate=0.07276510507381276, max_depth=4, min_child_weight=89, n_estimators=116, subsample=0.6485237799703186;, score=-0.693 total time=  18.6s\n",
      "[CV 1/3] END colsample_bytree=0.9188127789408888, learning_rate=0.44250809728808527, max_depth=22, min_child_weight=39, n_estimators=819, subsample=0.6796472533457819;, score=-0.838 total time=13.5min\n",
      "[CV 2/3] END colsample_bytree=0.9188127789408888, learning_rate=0.44250809728808527, max_depth=22, min_child_weight=39, n_estimators=819, subsample=0.6796472533457819;, score=-0.837 total time=13.3min\n",
      "[CV 3/3] END colsample_bytree=0.9188127789408888, learning_rate=0.44250809728808527, max_depth=22, min_child_weight=39, n_estimators=819, subsample=0.6796472533457819;, score=-0.838 total time=13.4min\n",
      "[CV 1/3] END colsample_bytree=0.7501457388987571, learning_rate=0.4493813317648964, max_depth=15, min_child_weight=88, n_estimators=487, subsample=1.160768398403826;, score=nan total time=   4.5s\n",
      "[CV 2/3] END colsample_bytree=0.7501457388987571, learning_rate=0.4493813317648964, max_depth=15, min_child_weight=88, n_estimators=487, subsample=1.160768398403826;, score=nan total time=   4.4s\n",
      "[CV 3/3] END colsample_bytree=0.7501457388987571, learning_rate=0.4493813317648964, max_depth=15, min_child_weight=88, n_estimators=487, subsample=1.160768398403826;, score=nan total time=   4.6s\n",
      "[CV 1/3] END colsample_bytree=0.9829623563060101, learning_rate=0.42335700594125336, max_depth=4, min_child_weight=21, n_estimators=860, subsample=0.8517600374566738;, score=-0.700 total time= 1.6min\n",
      "[CV 2/3] END colsample_bytree=0.9829623563060101, learning_rate=0.42335700594125336, max_depth=4, min_child_weight=21, n_estimators=860, subsample=0.8517600374566738;, score=-0.700 total time= 1.6min\n",
      "[CV 3/3] END colsample_bytree=0.9829623563060101, learning_rate=0.42335700594125336, max_depth=4, min_child_weight=21, n_estimators=860, subsample=0.8517600374566738;, score=-0.701 total time= 1.6min\n",
      "[CV 1/3] END colsample_bytree=0.7486385937006944, learning_rate=0.2947781429210093, max_depth=4, min_child_weight=85, n_estimators=696, subsample=0.805127800029841;, score=-0.696 total time= 1.3min\n",
      "[CV 2/3] END colsample_bytree=0.7486385937006944, learning_rate=0.2947781429210093, max_depth=4, min_child_weight=85, n_estimators=696, subsample=0.805127800029841;, score=-0.695 total time= 1.3min\n",
      "[CV 1/3] END colsample_bytree=0.8569886849640647, learning_rate=0.5607999206122931, max_depth=0, min_child_weight=57, n_estimators=633, subsample=0.6938622256026516;, score=-0.890 total time=19.9min\n",
      "[CV 3/3] END colsample_bytree=0.7486385937006944, learning_rate=0.2947781429210093, max_depth=4, min_child_weight=85, n_estimators=696, subsample=0.805127800029841;, score=-0.696 total time= 1.4min\n",
      "[CV 2/3] END colsample_bytree=0.8569886849640647, learning_rate=0.5607999206122931, max_depth=0, min_child_weight=57, n_estimators=633, subsample=0.6938622256026516;, score=-0.891 total time=20.0min\n",
      "[CV 3/3] END colsample_bytree=0.8569886849640647, learning_rate=0.5607999206122931, max_depth=0, min_child_weight=57, n_estimators=633, subsample=0.6938622256026516;, score=-0.890 total time=20.1min\n",
      "[CV 1/3] END colsample_bytree=0.6550794394880651, learning_rate=0.0853255906148481, max_depth=29, min_child_weight=61, n_estimators=452, subsample=0.8845042974523951;, score=-0.710 total time=11.3min\n",
      "[CV 1/3] END colsample_bytree=0.6587004963906009, learning_rate=0.4032927000934659, max_depth=6, min_child_weight=99, n_estimators=288, subsample=0.8788042877637667;, score=-0.701 total time=  46.6s\n",
      "[CV 2/3] END colsample_bytree=0.6587004963906009, learning_rate=0.4032927000934659, max_depth=6, min_child_weight=99, n_estimators=288, subsample=0.8788042877637667;, score=-0.700 total time=  47.0s\n",
      "[CV 2/3] END colsample_bytree=0.6550794394880651, learning_rate=0.0853255906148481, max_depth=29, min_child_weight=61, n_estimators=452, subsample=0.8845042974523951;, score=-0.709 total time=11.5min\n",
      "[CV 3/3] END colsample_bytree=0.6587004963906009, learning_rate=0.4032927000934659, max_depth=6, min_child_weight=99, n_estimators=288, subsample=0.8788042877637667;, score=-0.701 total time=  47.1s\n",
      "[CV 1/3] END colsample_bytree=0.989864209585658, learning_rate=0.048447139357626984, max_depth=21, min_child_weight=68, n_estimators=99, subsample=0.6271824058632267;, score=-0.696 total time= 1.6min\n",
      "[CV 2/3] END colsample_bytree=0.989864209585658, learning_rate=0.048447139357626984, max_depth=21, min_child_weight=68, n_estimators=99, subsample=0.6271824058632267;, score=-0.696 total time= 1.7min\n",
      "[CV 3/3] END colsample_bytree=0.989864209585658, learning_rate=0.048447139357626984, max_depth=21, min_child_weight=68, n_estimators=99, subsample=0.6271824058632267;, score=-0.697 total time= 1.8min\n",
      "[CV 3/3] END colsample_bytree=0.6550794394880651, learning_rate=0.0853255906148481, max_depth=29, min_child_weight=61, n_estimators=452, subsample=0.8845042974523951;, score=-0.711 total time=11.7min\n",
      "[CV 1/3] END colsample_bytree=1.0103782616388846, learning_rate=0.502680931511931, max_depth=15, min_child_weight=1, n_estimators=496, subsample=1.1203193601330024;, score=nan total time=   4.3s\n",
      "[CV 2/3] END colsample_bytree=1.0103782616388846, learning_rate=0.502680931511931, max_depth=15, min_child_weight=1, n_estimators=496, subsample=1.1203193601330024;, score=nan total time=   4.2s\n",
      "[CV 3/3] END colsample_bytree=1.0103782616388846, learning_rate=0.502680931511931, max_depth=15, min_child_weight=1, n_estimators=496, subsample=1.1203193601330024;, score=nan total time=   4.3s\n",
      "[CV 1/3] END colsample_bytree=0.8247675687758826, learning_rate=0.5106879325713891, max_depth=25, min_child_weight=95, n_estimators=768, subsample=0.9236264690400375;, score=-0.813 total time=11.7min\n",
      "[CV 2/3] END colsample_bytree=0.8247675687758826, learning_rate=0.5106879325713891, max_depth=25, min_child_weight=95, n_estimators=768, subsample=0.9236264690400375;, score=-0.812 total time=11.8min\n",
      "[CV 1/3] END colsample_bytree=0.9818421584676067, learning_rate=0.6507594357459199, max_depth=11, min_child_weight=49, n_estimators=674, subsample=0.985972931065412;, score=-0.838 total time= 3.7min\n",
      "[CV 1/3] END colsample_bytree=0.87495173429491, learning_rate=0.446493431452748, max_depth=4, min_child_weight=11, n_estimators=834, subsample=1.0922561062627607;, score=nan total time=   3.9s\n",
      "[CV 2/3] END colsample_bytree=0.87495173429491, learning_rate=0.446493431452748, max_depth=4, min_child_weight=11, n_estimators=834, subsample=1.0922561062627607;, score=nan total time=   3.7s\n",
      "[CV 3/3] END colsample_bytree=0.87495173429491, learning_rate=0.446493431452748, max_depth=4, min_child_weight=11, n_estimators=834, subsample=1.0922561062627607;, score=nan total time=   3.4s\n",
      "[CV 3/3] END colsample_bytree=0.8247675687758826, learning_rate=0.5106879325713891, max_depth=25, min_child_weight=95, n_estimators=768, subsample=0.9236264690400375;, score=-0.812 total time=11.6min\n",
      "[CV 2/3] END colsample_bytree=0.9818421584676067, learning_rate=0.6507594357459199, max_depth=11, min_child_weight=49, n_estimators=674, subsample=0.985972931065412;, score=-0.838 total time= 3.4min\n",
      "[CV 1/3] END colsample_bytree=0.9908908631146727, learning_rate=0.17534748790139632, max_depth=28, min_child_weight=12, n_estimators=11, subsample=0.6604668008264559;, score=-0.719 total time= 3.0min\n",
      "[CV 3/3] END colsample_bytree=0.9818421584676067, learning_rate=0.6507594357459199, max_depth=11, min_child_weight=49, n_estimators=674, subsample=0.985972931065412;, score=-0.838 total time= 3.3min\n",
      "[CV 2/3] END colsample_bytree=0.9908908631146727, learning_rate=0.17534748790139632, max_depth=28, min_child_weight=12, n_estimators=11, subsample=0.6604668008264559;, score=-0.717 total time= 3.3min\n",
      "[CV 1/3] END colsample_bytree=0.6109330953909298, learning_rate=0.08555436860474272, max_depth=2, min_child_weight=86, n_estimators=848, subsample=0.9934335812284453;, score=-0.694 total time=  55.8s\n",
      "[CV 2/3] END colsample_bytree=0.6109330953909298, learning_rate=0.08555436860474272, max_depth=2, min_child_weight=86, n_estimators=848, subsample=0.9934335812284453;, score=-0.693 total time= 1.0min\n",
      "[CV 3/3] END colsample_bytree=0.9908908631146727, learning_rate=0.17534748790139632, max_depth=28, min_child_weight=12, n_estimators=11, subsample=0.6604668008264559;, score=-0.720 total time= 1.2min\n",
      "[CV 3/3] END colsample_bytree=0.6109330953909298, learning_rate=0.08555436860474272, max_depth=2, min_child_weight=86, n_estimators=848, subsample=0.9934335812284453;, score=-0.694 total time= 1.0min\n",
      "[CV 1/3] END colsample_bytree=0.6708988965729937, learning_rate=0.5673897322913205, max_depth=12, min_child_weight=74, n_estimators=412, subsample=0.6235117960053878;, score=-0.888 total time= 2.9min\n",
      "[CV 1/3] END colsample_bytree=0.831237972579339, learning_rate=0.5552909351782318, max_depth=29, min_child_weight=33, n_estimators=114, subsample=0.76911286486404;, score=-0.860 total time= 4.4min\n",
      "[CV 2/3] END colsample_bytree=0.831237972579339, learning_rate=0.5552909351782318, max_depth=29, min_child_weight=33, n_estimators=114, subsample=0.76911286486404;, score=-0.859 total time= 4.7min\n",
      "[CV 3/3] END colsample_bytree=0.831237972579339, learning_rate=0.5552909351782318, max_depth=29, min_child_weight=33, n_estimators=114, subsample=0.76911286486404;, score=-0.861 total time= 4.7min\n",
      "[CV 1/3] END colsample_bytree=0.8507676190293472, learning_rate=0.784064441216198, max_depth=3, min_child_weight=9, n_estimators=868, subsample=1.050368850984515;, score=nan total time=   3.4s\n",
      "[CV 2/3] END colsample_bytree=0.8507676190293472, learning_rate=0.784064441216198, max_depth=3, min_child_weight=9, n_estimators=868, subsample=1.050368850984515;, score=nan total time=   3.3s\n",
      "[CV 3/3] END colsample_bytree=0.8507676190293472, learning_rate=0.784064441216198, max_depth=3, min_child_weight=9, n_estimators=868, subsample=1.050368850984515;, score=nan total time=   3.1s\n",
      "[CV 1/3] END colsample_bytree=1.0841008435603583, learning_rate=0.8024041136005386, max_depth=15, min_child_weight=35, n_estimators=977, subsample=0.7500098695296628;, score=nan total time=   3.0s\n",
      "[CV 2/3] END colsample_bytree=1.0841008435603583, learning_rate=0.8024041136005386, max_depth=15, min_child_weight=35, n_estimators=977, subsample=0.7500098695296628;, score=nan total time=   3.4s\n",
      "[CV 3/3] END colsample_bytree=1.0841008435603583, learning_rate=0.8024041136005386, max_depth=15, min_child_weight=35, n_estimators=977, subsample=0.7500098695296628;, score=nan total time=   3.1s\n",
      "[CV 1/3] END colsample_bytree=0.9483264074063459, learning_rate=0.7036932857677777, max_depth=4, min_child_weight=11, n_estimators=368, subsample=1.0079068679401475;, score=nan total time=   3.1s\n",
      "[CV 2/3] END colsample_bytree=0.9483264074063459, learning_rate=0.7036932857677777, max_depth=4, min_child_weight=11, n_estimators=368, subsample=1.0079068679401475;, score=nan total time=   3.1s\n",
      "[CV 3/3] END colsample_bytree=0.9483264074063459, learning_rate=0.7036932857677777, max_depth=4, min_child_weight=11, n_estimators=368, subsample=1.0079068679401475;, score=nan total time=   3.0s\n",
      "[CV 1/3] END colsample_bytree=1.0439452562684246, learning_rate=0.20058892192318356, max_depth=29, min_child_weight=16, n_estimators=880, subsample=0.9031514234687142;, score=nan total time=   2.9s\n",
      "[CV 2/3] END colsample_bytree=1.0439452562684246, learning_rate=0.20058892192318356, max_depth=29, min_child_weight=16, n_estimators=880, subsample=0.9031514234687142;, score=nan total time=   3.0s\n",
      "[CV 3/3] END colsample_bytree=1.0439452562684246, learning_rate=0.20058892192318356, max_depth=29, min_child_weight=16, n_estimators=880, subsample=0.9031514234687142;, score=nan total time=   3.1s\n",
      "[CV 1/3] END colsample_bytree=1.095874479664645, learning_rate=0.2660396808244894, max_depth=26, min_child_weight=18, n_estimators=176, subsample=0.6320911780484213;, score=nan total time=   3.0s\n",
      "[CV 2/3] END colsample_bytree=1.095874479664645, learning_rate=0.2660396808244894, max_depth=26, min_child_weight=18, n_estimators=176, subsample=0.6320911780484213;, score=nan total time=   2.9s\n",
      "[CV 3/3] END colsample_bytree=1.095874479664645, learning_rate=0.2660396808244894, max_depth=26, min_child_weight=18, n_estimators=176, subsample=0.6320911780484213;, score=nan total time=   3.1s\n",
      "[CV 1/3] END colsample_bytree=1.175124898129919, learning_rate=0.6877145152764719, max_depth=8, min_child_weight=70, n_estimators=795, subsample=1.1700371802304828;, score=nan total time=   3.1s\n",
      "[CV 2/3] END colsample_bytree=1.175124898129919, learning_rate=0.6877145152764719, max_depth=8, min_child_weight=70, n_estimators=795, subsample=1.1700371802304828;, score=nan total time=   3.0s\n",
      "[CV 3/3] END colsample_bytree=1.175124898129919, learning_rate=0.6877145152764719, max_depth=8, min_child_weight=70, n_estimators=795, subsample=1.1700371802304828;, score=nan total time=   2.9s\n",
      "[CV 1/3] END colsample_bytree=1.1703642881625336, learning_rate=0.4687503104986289, max_depth=14, min_child_weight=15, n_estimators=884, subsample=0.6550224883550886;, score=nan total time=   3.1s\n",
      "[CV 2/3] END colsample_bytree=1.1703642881625336, learning_rate=0.4687503104986289, max_depth=14, min_child_weight=15, n_estimators=884, subsample=0.6550224883550886;, score=nan total time=   2.9s\n",
      "[CV 3/3] END colsample_bytree=1.1703642881625336, learning_rate=0.4687503104986289, max_depth=14, min_child_weight=15, n_estimators=884, subsample=0.6550224883550886;, score=nan total time=   3.0s\n",
      "[CV 1/3] END colsample_bytree=0.9614645555406713, learning_rate=0.45296244187664064, max_depth=20, min_child_weight=99, n_estimators=564, subsample=1.074947426235509;, score=nan total time=   3.0s\n",
      "[CV 2/3] END colsample_bytree=0.9614645555406713, learning_rate=0.45296244187664064, max_depth=20, min_child_weight=99, n_estimators=564, subsample=1.074947426235509;, score=nan total time=   3.1s\n",
      "[CV 3/3] END colsample_bytree=0.9614645555406713, learning_rate=0.45296244187664064, max_depth=20, min_child_weight=99, n_estimators=564, subsample=1.074947426235509;, score=nan total time=   2.9s\n",
      "[CV 1/3] END colsample_bytree=1.0737708856767323, learning_rate=0.0829648824389523, max_depth=9, min_child_weight=57, n_estimators=934, subsample=1.1975587452181973;, score=nan total time=   3.0s\n",
      "[CV 2/3] END colsample_bytree=1.0737708856767323, learning_rate=0.0829648824389523, max_depth=9, min_child_weight=57, n_estimators=934, subsample=1.1975587452181973;, score=nan total time=   3.1s\n",
      "[CV 3/3] END colsample_bytree=1.0737708856767323, learning_rate=0.0829648824389523, max_depth=9, min_child_weight=57, n_estimators=934, subsample=1.1975587452181973;, score=nan total time=   3.1s\n",
      "[CV 1/3] END colsample_bytree=0.63352269280641, learning_rate=0.5996284454328071, max_depth=28, min_child_weight=74, n_estimators=657, subsample=1.181191166384481;, score=nan total time=   3.0s\n",
      "[CV 2/3] END colsample_bytree=0.63352269280641, learning_rate=0.5996284454328071, max_depth=28, min_child_weight=74, n_estimators=657, subsample=1.181191166384481;, score=nan total time=   2.9s\n",
      "[CV 3/3] END colsample_bytree=0.63352269280641, learning_rate=0.5996284454328071, max_depth=28, min_child_weight=74, n_estimators=657, subsample=1.181191166384481;, score=nan total time=   2.8s\n",
      "[CV 2/3] END colsample_bytree=0.6708988965729937, learning_rate=0.5673897322913205, max_depth=12, min_child_weight=74, n_estimators=412, subsample=0.6235117960053878;, score=-0.886 total time= 2.2min\n",
      "[CV 1/3] END colsample_bytree=1.0128180061050234, learning_rate=0.6795710993898991, max_depth=16, min_child_weight=6, n_estimators=173, subsample=1.020581478875472;, score=nan total time=   2.7s\n",
      "[CV 2/3] END colsample_bytree=1.0128180061050234, learning_rate=0.6795710993898991, max_depth=16, min_child_weight=6, n_estimators=173, subsample=1.020581478875472;, score=nan total time=   2.6s\n",
      "[CV 3/3] END colsample_bytree=1.0128180061050234, learning_rate=0.6795710993898991, max_depth=16, min_child_weight=6, n_estimators=173, subsample=1.020581478875472;, score=nan total time=   2.8s\n",
      "[CV 3/3] END colsample_bytree=0.6708988965729937, learning_rate=0.5673897322913205, max_depth=12, min_child_weight=74, n_estimators=412, subsample=0.6235117960053878;, score=-0.888 total time= 2.0min\n",
      "[CV 1/3] END colsample_bytree=0.7399368434547167, learning_rate=0.47504433378142585, max_depth=12, min_child_weight=64, n_estimators=341, subsample=1.0876797403545015;, score=nan total time=   5.3s\n",
      "[CV 2/3] END colsample_bytree=0.7399368434547167, learning_rate=0.47504433378142585, max_depth=12, min_child_weight=64, n_estimators=341, subsample=1.0876797403545015;, score=nan total time=   4.9s\n",
      "[CV 3/3] END colsample_bytree=0.7399368434547167, learning_rate=0.47504433378142585, max_depth=12, min_child_weight=64, n_estimators=341, subsample=1.0876797403545015;, score=nan total time=   4.7s\n",
      "[CV 1/3] END colsample_bytree=1.168349146430315, learning_rate=0.7988008510582968, max_depth=3, min_child_weight=35, n_estimators=69, subsample=1.0249087173499198;, score=nan total time=   4.6s\n",
      "[CV 2/3] END colsample_bytree=1.168349146430315, learning_rate=0.7988008510582968, max_depth=3, min_child_weight=35, n_estimators=69, subsample=1.0249087173499198;, score=nan total time=   4.5s\n",
      "[CV 3/3] END colsample_bytree=1.168349146430315, learning_rate=0.7988008510582968, max_depth=3, min_child_weight=35, n_estimators=69, subsample=1.0249087173499198;, score=nan total time=   4.5s\n",
      "[CV 1/3] END colsample_bytree=0.8890001927784692, learning_rate=0.3123900720978036, max_depth=6, min_child_weight=90, n_estimators=713, subsample=1.1438126310568415;, score=nan total time=   4.6s\n",
      "[CV 2/3] END colsample_bytree=0.8890001927784692, learning_rate=0.3123900720978036, max_depth=6, min_child_weight=90, n_estimators=713, subsample=1.1438126310568415;, score=nan total time=   4.4s\n",
      "[CV 3/3] END colsample_bytree=0.8890001927784692, learning_rate=0.3123900720978036, max_depth=6, min_child_weight=90, n_estimators=713, subsample=1.1438126310568415;, score=nan total time=   4.7s\n",
      "[CV 1/3] END colsample_bytree=0.6667184893836908, learning_rate=0.40410008343268733, max_depth=12, min_child_weight=91, n_estimators=637, subsample=0.6337819654091024;, score=-0.819 total time= 4.0min\n",
      "[CV 1/3] END colsample_bytree=0.6436578038185161, learning_rate=0.6674880474322851, max_depth=25, min_child_weight=65, n_estimators=516, subsample=0.9079957012154357;, score=-0.866 total time= 9.3min\n",
      "[CV 3/3] END colsample_bytree=0.6436578038185161, learning_rate=0.6674880474322851, max_depth=25, min_child_weight=65, n_estimators=516, subsample=0.9079957012154357;, score=-0.867 total time= 9.3min\n",
      "[CV 2/3] END colsample_bytree=0.6436578038185161, learning_rate=0.6674880474322851, max_depth=25, min_child_weight=65, n_estimators=516, subsample=0.9079957012154357;, score=-0.867 total time= 9.3min\n",
      "[CV 1/3] END colsample_bytree=0.6712907497608431, learning_rate=0.1040209974216839, max_depth=8, min_child_weight=38, n_estimators=0, subsample=1.0086236562581454;, score=nan total time=   3.0s\n",
      "[CV 2/3] END colsample_bytree=0.6712907497608431, learning_rate=0.1040209974216839, max_depth=8, min_child_weight=38, n_estimators=0, subsample=1.0086236562581454;, score=nan total time=   3.0s\n",
      "[CV 3/3] END colsample_bytree=0.6712907497608431, learning_rate=0.1040209974216839, max_depth=8, min_child_weight=38, n_estimators=0, subsample=1.0086236562581454;, score=nan total time=   3.3s\n",
      "[CV 2/3] END colsample_bytree=0.6667184893836908, learning_rate=0.40410008343268733, max_depth=12, min_child_weight=91, n_estimators=637, subsample=0.6337819654091024;, score=-0.819 total time= 4.0min\n",
      "[CV 3/3] END colsample_bytree=0.6667184893836908, learning_rate=0.40410008343268733, max_depth=12, min_child_weight=91, n_estimators=637, subsample=0.6337819654091024;, score=-0.820 total time= 3.1min\n",
      "[CV 2/3] END colsample_bytree=0.742503882775482, learning_rate=0.3301783142976199, max_depth=27, min_child_weight=24, n_estimators=823, subsample=0.9170220727783255;, score=-0.762 total time=33.1min\n",
      "[CV 3/3] END colsample_bytree=0.742503882775482, learning_rate=0.3301783142976199, max_depth=27, min_child_weight=24, n_estimators=823, subsample=0.9170220727783255;, score=-0.765 total time=33.9min\n",
      "[CV 1/3] END colsample_bytree=0.742503882775482, learning_rate=0.3301783142976199, max_depth=27, min_child_weight=24, n_estimators=823, subsample=0.9170220727783255;, score=-0.763 total time=34.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:547: FitFailedWarning: \n",
      "159 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.02484 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.18425 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.01054 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.06508 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.1637 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.19213 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.06335 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.02681 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.13233 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.03304 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.05333 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.15782 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.18597 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.00842 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.00328 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.10118 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.10263 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.1264 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.13833 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.14025 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.13827 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.16138 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.02731 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.03256 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.07689 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.03347 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.19673 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.17184 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.11181 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.01762 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.02149 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.07898 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.13197 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.062 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.18172 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.16077 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.01038 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.09226 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.05037 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.0841 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.00791 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.04395 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.09587 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.17512 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.17036 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.07495 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.07377 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.18119 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.01282 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.08768 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.16835 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.14381 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/training.py\", line 192, in train\n",
      "    return bst.copy()\n",
      "           ^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 1881, in copy\n",
      "    return copy.copy(self)\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/Cellar/python@3.11/3.11.3/Frameworks/Python.framework/Versions/3.11/lib/python3.11/copy.py\", line 84, in copy\n",
      "    return copier(x)\n",
      "           ^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 1867, in __copy__\n",
      "    return self.__deepcopy__(None)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 1871, in __deepcopy__\n",
      "    return Booster(model_file=self)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 1672, in __init__\n",
      "    state = model_file.__getstate__()\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 1763, in __getstate__\n",
      "    _check_call(\n",
      "  File \"/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.00862 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/dkamboj6/Recitation/ECE-461P-Term-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [-0.87025196 -0.69581268         nan -0.91918588         nan -0.70924391\n",
      " -0.70229475 -1.03051661         nan -0.72967254         nan         nan\n",
      " -0.79859052 -0.85403539         nan         nan         nan -0.84506148\n",
      " -0.70034575         nan         nan -0.76583799 -0.79388347         nan\n",
      "         nan -0.86677039 -0.74038917 -0.83861877 -0.89169627 -0.70523902\n",
      " -0.72480271         nan         nan         nan -1.06347731         nan\n",
      " -0.74133618 -0.72279069         nan         nan         nan         nan\n",
      "         nan         nan -0.84874315         nan         nan -0.82224573\n",
      " -0.89065644         nan         nan         nan         nan         nan\n",
      "         nan -0.71030051         nan -0.75508761         nan         nan\n",
      " -0.82309215 -1.14042214 -0.86518527         nan -0.83784465         nan\n",
      " -0.69218888 -0.89044538         nan -0.70008059 -0.69557913 -0.71011977\n",
      " -0.7006807  -0.69651654 -0.81220287         nan -0.83791446         nan\n",
      " -0.71862669 -0.69364438 -0.8598911  -0.88754054         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan -0.86665781         nan         nan\n",
      "         nan -0.81950308         nan -0.76313104]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          callbacks=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None, device=None,\n",
       "                                          early_stopping_rounds=None,\n",
       "                                          enable_categorical=False,\n",
       "                                          eval_metric=None, feature_types=None,\n",
       "                                          gamma=None, grow_policy=None,\n",
       "                                          importance_type=None,\n",
       "                                          interaction_constraints=None,\n",
       "                                          learning_rate=...\n",
       "                                        &#x27;min_child_weight&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x141ca6e90&gt;,\n",
       "                                        &#x27;n_estimators&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x142d3b450&gt;,\n",
       "                                        &#x27;subsample&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x14271a710&gt;},\n",
       "                   random_state=42,\n",
       "                   scoring=make_scorer(rmsle_scorer, greater_is_better=False, response_method=&#x27;predict&#x27;),\n",
       "                   verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomizedSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\">?<span>Documentation for RandomizedSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          callbacks=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None, device=None,\n",
       "                                          early_stopping_rounds=None,\n",
       "                                          enable_categorical=False,\n",
       "                                          eval_metric=None, feature_types=None,\n",
       "                                          gamma=None, grow_policy=None,\n",
       "                                          importance_type=None,\n",
       "                                          interaction_constraints=None,\n",
       "                                          learning_rate=...\n",
       "                                        &#x27;min_child_weight&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x141ca6e90&gt;,\n",
       "                                        &#x27;n_estimators&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x142d3b450&gt;,\n",
       "                                        &#x27;subsample&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x14271a710&gt;},\n",
       "                   random_state=42,\n",
       "                   scoring=make_scorer(rmsle_scorer, greater_is_better=False, response_method=&#x27;predict&#x27;),\n",
       "                   verbose=3)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=10,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">XGBRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=10,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          callbacks=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None, device=None,\n",
       "                                          early_stopping_rounds=None,\n",
       "                                          enable_categorical=False,\n",
       "                                          eval_metric=None, feature_types=None,\n",
       "                                          gamma=None, grow_policy=None,\n",
       "                                          importance_type=None,\n",
       "                                          interaction_constraints=None,\n",
       "                                          learning_rate=...\n",
       "                                        'min_child_weight': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x141ca6e90>,\n",
       "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x142d3b450>,\n",
       "                                        'subsample': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x14271a710>},\n",
       "                   random_state=42,\n",
       "                   scoring=make_scorer(rmsle_scorer, greater_is_better=False, response_method='predict'),\n",
       "                   verbose=3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import randint, uniform\n",
    "\n",
    "param_dist = {\n",
    "    'max_depth': randint(0, 30),\n",
    "    'min_child_weight': randint(0, 100),\n",
    "    'subsample': uniform(0.6, 0.6),\n",
    "    'colsample_bytree': uniform(0.6, 0.6),\n",
    "    'learning_rate': uniform(0.01, 0.8),\n",
    "    'n_estimators': randint(0,1000)\n",
    "}\n",
    "\n",
    "# Create the RMSLE scorer\n",
    "def rmsle_scorer(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.power(y_pred - y_true, 2)))\n",
    "\n",
    "rmsle_scoring = make_scorer(rmsle_scorer, greater_is_better=False)\n",
    "\n",
    "# Initialize the XGBoost Regressor\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', n_jobs=10)\n",
    "\n",
    "# Setup RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=xgb_model, param_distributions=param_dist, \n",
    "                                   n_iter=100, scoring=rmsle_scoring, cv=3, verbose=3, random_state=42,n_jobs=4)\n",
    "\n",
    "# Fit the model\n",
    "random_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model parameters: {'colsample_bytree': 0.8633828524233816, 'learning_rate': 0.07276510507381276, 'max_depth': 4, 'min_child_weight': 89, 'n_estimators': 116, 'subsample': 0.6485237799703186}\n",
      "Test RMSLE: 0.6914452374609846\n"
     ]
    }
   ],
   "source": [
    "best_model = random_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "test_rmsle = rmsle_scorer(y_test, y_pred)\n",
    "\n",
    "print(\"Best model parameters:\", random_search.best_params_)\n",
    "print(\"Test RMSLE:\", test_rmsle)\n",
    "\n",
    "# Best model parameters: {'colsample_bytree': 0.8633828524233816, 'learning_rate': 0.07276510507381276, 'max_depth': 4, 'min_child_weight': 89, 'n_estimators': 116, 'subsample': 0.6485237799703186}\n",
    "# Test RMSLE: 0.6914452374609846\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
